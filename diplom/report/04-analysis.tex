\chapter{Аналитический раздел}

\section{Особенности управление памятью}

\subsection{Управление памятью в операционных системах}

Виртуальная память представляет собой ключевую концепцию в управлении памятью современных компьютерных систем~\cite{noor202512}.
Она позволяет программам использовать объем оперативной памяти, превышающий физически доступный, за счет автоматического перемещения данных между основной памятью
и вторичным хранилищем.
Это достигается благодаря использованию виртуальных адресов, которые транслируются в физические адреса с помощью аппаратных средств.

Каждая программа работает с собственным адресным пространством, которое разбивается на страницы, представляющие собой непрерывные диапазоны адресов.
Эти страницы не обязательно должны все одновременно находиться в оперативной памяти для выполнения программы, что позволяет эффективно использовать доступную память.

Когда программа обращается к данным, которые уже находятся в физической памяти, аппаратное обеспечение обеспечивает необходимое отображение адресов.
Когда программа пытается получить доступ к странице, которая присутствует в виртуальном адресном пространстве, но отсутствует в физической памяти возникает системное прерывания отсутствия страницы после чего управление передается операционной системе.

Операционная система реагирует на ошибку отсутствия страницы, выбирая страницу при помощи алгоритма замещения и сбрасывая её содержимое на диск, если оно уже не находится там. 
Затем система извлекает нужную страницу с диска и помещает её в освободившееся место в памяти. 
После этого в таблицы вносятся соответствующие изменения, и прерванная команда выполняется заново.

Таблица страниц содержит сведения о каждой странице, включая номер страничного блока, который является ключевым элементом страничного отображения.
Также в информации содержится бит присутствия-отсутствия, если он равен 1, запись активна и может быть использована, иначе соответствующая виртуальная страница в данный момент отсутствует в памяти, и любое обращение к такой записи вызывает ошибку отсутствия страницы. 
Биты защиты указывают на тип доступа, который разрешен для страницы. 
В самом простом случае это один бит, который равен 0 для чтения-записи и 1 для только чтения.
В более сложных системах могут быть использованы три бита,
каждый из которых разрешает чтение, запись или исполнение страницы. 
Биты модификации и ссылки служат для отслеживания использования страницы.
Бит модификации автоматически устанавливается при записи в страницу и помогает операционной системе определить, нужно ли сохранять страницу на диск при ее выгрузке из памяти. 
Бит ссылки устанавливается при любом обращении к странице и помогает операционной системе определить, какую страницу следует выгрузить при возникновении ошибки отсутствия страницы.

Большинство программ часто обращаются к ограниченному
набору страниц.
Из-за этого только небольшая часть записей в таблице страниц активно используется, а остальная практически не задействуется.
Основываясь на этом наблюдении,  для повышения производительности системы было
предложены добавить в аппаратуру специальное устройство, которое называется TLB, и отвечает за трансляцию виртуальных адресов в физические для самых используемых страниц.

При использовании TLB существует 2 типа ошибок: программные и аппаратные.
Программная ошибка возникает, когда страница отсутствует в TLB, но есть в памяти, и ее можно исправить простым
обновлением TLB без обращения к диску. 
Это занимает 10-20 машинных команд и несколько наносекунд.
Аппаратная ошибка возникает, когда страница отсутствует в памяти и требуется обращение к диску, что занимает несколько миллисекунд.
Она обрабатывается значительно медленнее программной ошибки.

При возникновении ошибки отсутствия страницы, операционная система должна определить, какую страницу из памяти исключить, чтобы освободить место для загружаемой страницы.
Если страница, которую нужно заместить, была изменена с момента загрузки в память, то ее содержимое должно быть обновлено на диске.
Если страница не подвергалась изменениям и дисковая копия актуальна, то перезапись не требуется.
В этом случае новая страница просто замещает старую.

\subsection{Управление памятью в PostgreSQL}

Разделяемый кэш буфер сохраняет страницы в оперативной памяти, доступ к которой в сотни тысяч раз быстрее, чем к дисковому хранилищу, где содержится вся информация о состоянии базы данных~\cite{shaik2020postgresql}.

В операционной системе также есть дисковый кэш, который решает ту же проблему, поэтому системы управления базами данных обычно стараются избежать двойного кэширования, обращаясь к дискам напрямую, а не через кэш ОС. 
В случае с PostgreSQL это не так: все данные читаются и записываются с помощью обычных файловых операций~\cite{rogov2023postgresql}.
Схема взаимодействия разделяемого кэш буфера и кэша уровня операционной системы представлена на рисунке~\ref{img:shared_buffers}.

\includeimage
{shared_buffers} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.5\textwidth} % Ширина рисунка
{Схема взаимодействия разделяемого кэш буфера с ОС} % Подпись рисунка

Пои чтении страница сначала ищется в кэш буфере, если она там не находится, то отправляется запрос операционной системе на чтение страницы.
Если операционная система находит ее в своем кэше, то данные сразу копируются в кэш буфер PostgreSQL, иначе операционная система загружает данные с диска в свой кэш и затем они копируются и попадает в разделяемый кэш буфер.

Для записи содержимого буфера на диск используется три процесса:
\begin{itemize}
	\item user backend;
	\item bgwriter;
	\item checkpointer.
\end{itemize}

Процесс user backend обрабатывает пользовательские соединения.
В случае запросов, которые изменяют данные, процесс user backend помечает измененные страницы для дальнейшей записи на диск.
В случае, когда процессу надо исключить одну страницу из буфера и записать другую и страница для замещения помечена как измененная, user backend сам инициирует процесс копирования в кэш операционной системы для дальнейшей записи на диск.

Процесс bgwriter работает в фоновом режиме и нужен для снижения нагрузки на user backend и checkpointer.
Он запускается раз в некоторый промежуток времени, который устанавливается через конфигурационный файл, просматривает, какие страницы были изменены и записывает их в кэш операционной системы для дальнейшей записи на диск.

Процесс checkpointer отвечает за создание контрольных точек, когда данные гарантированно записываются на диск.
В момент вызова контрольной точки все измененные страницы записываются на диск и в лог файл добавляет специальная запись о контрольной точке.
Все изменения, сделанные до этой записи, гарантировано записаны на диск.

Для восстановления после аварийного завершения в PostgreSQL используется механизм Write ahead logging.
Все изменения перед внесением в страницы в разделяемом кэш буфере записываются в специальный лог файл.
После прохождения очередной контрольной точки все изменения гарантировано синхронизированы с диском и записи, предшествующие этой точке, могут быть удалены из лог файла.

Контрольная точка создается в следующих случаях:
\begin{itemize}
	\item явный вызов команды checkpoint;
	\item по истечению таймера, который задается в конфигурационном файле, по умолчанию -- 300 секунд;
	\item размер write ahead log файла достиг максимального размера, заданного в конфигурационном файле;
	\item вызов функции pg\_start\_backup;
	\item вызов команды pg\_basebackup;
	\item вызов команды завершения работы СУБД;
	\item при вызове команд создания и удаления базы данных.
\end{itemize}

Проблема двойного кэширования отчасти решается тем, что пока страница находится в разделяемом кэш буфере все обращения к ней идут через него и кэш уровня операционной системы задействован не будет.
В следствии этого, рано или поздно страница будет исключена из кэша уровня операционной системы, так как к ней не будет обращений.

Буферный кэш является списком блоков.
Каждый блок содержит страницу с данными и заголовок.
Заголовок содержит:
\begin{itemize}
	\item номер блока страницы;
	\item индикатор того, что страница была изменена, но еще не записана на диск;
	\item число обращений к странице;
	\item число активных операций или транзакций, которые используют страницу. 
\end{itemize}

При старте все блоки в буферном кэше помещаются в список свободных.
Для поиска нужной страницы используется хэш таблица.
В качестве ключа используются номер файла и номер страницы в файле.

При обращении к памяти процесс сначала пытается найти страницу в кэше.
Если она уже загружена, то счетчик обращений в заголовке соответствующего буфера увеличивается на единицу.
До тех пор, пока это счетчик не равен нулю, страница не может быть выгружена из кэша.

Если страница не была найдена в кэше, то она должна быть прочитана с диска в какой-то блок.
Если список свободных блоков не пуст, то будет взят первый из него, иначе требуется выбрать страницу, которая будет вытеснена из кэша.

В PostgreSQL для выбора кандидата на замещение анализируются два счетчика -- число обращений и количество использований.
Алгоритм часы поочередно проходит по всем страницам в кэше и, если оба счетчика равны нулю, то текущая страница будет замещена, иначе оба счетчика уменьшаются на единицу.
Для избежания большого числа проходов по всем страницам в поисках кандидата на замещение по умолчанию счетчики не могут быть больше пяти.

Когда кандидат на замещение найден, счетчик использований ассоциированного с ним блока устанавливается в 1, чтобы другие процессы не могли его использовать.
Если страница содержит измененную информацию, то запускается процесс переписывания в кэш ОС для дальнейшей записи на диск.
После этого новая страница загружается в буфер и для нее выставляется счетчик обращений в единицу.

\section{Методы замещения страниц}
\subsection{Оптимальный алгоритм}

Оптимальной алгоритм предлагает вытеснять страницу, которая будет без ссылок в течение самого длительного времени.
Этот алгоритм может быть реализован только во втором идентичном прогоне при условии использования истории  страниц полученной во время первого запуска. 
Когда система сталкивается с нагрузкой в режиме реального времени у нее этой истории нет, поэтому этот алгоритм не может быть реализован на практике.
Оптимальный алгоритм может быть использован для оценки других алгоритмов замещения страниц, которые могут быть применены и при первом прогоне.

\subsection{Алгоритм NRU}

Для того чтобы собирать статистику использования страниц виртуальной памяти, большинство компьютеров используют два бита состояния для каждой страницы.
Бит R устанавливается при обращении к странице, а бит M устанавливается, когда страница изменяется.

Если аппаратура не поддерживает эти биты, то они могут быть созданы с помощью механизмов операционной системы.
При запуске процесса все записи в его таблице страниц помечаются как отсутствующие в памяти.
Когда происходит обращение к странице, возникает ошибка отсутствия страницы, и операционная система устанавливает бит R, изменяет запись в таблице страниц, устанавливая режим доступа только для чтения, и перезапускает команду.
Если страница впоследствии изменяется, возникает другая ошибка страницы, позволяющая операционной системе установить бит M и изменить режим доступа к странице на чтение-запись.

Аналогичные биты хранятся в заголовке каждого блока в разделяемом кэш буфере PostgreSQL.
В качестве бита R можно использовать счетчик обращений, который будет сбрасываться по истечению определенного времени.
Для того, чтобы отметить страницы, которые были изменены в заголовке каждого блока присутствует специальный бит модификации.

Идея алгоритма Not Recently Used заключается в следующем: при запуске процесса оба этих бита для всех страниц
устанавливаются в 0. 
При каждом прерывании от таймера бит R сбрасывается, чтобы отличить страницы, к которым не было обращений в последнее время, от тех, к которым были такие обращения.

При возникновении ошибки отсутствия страницы операционная система анализирует все страницы и на основе текущих значений битов R и M разделяет их на четыре категории:
\begin{enumerate}
	\item К которым не было ни обращений, ни модификаций в последнее время.
	\item К которым не было обращений в последнее время, но были модификации.
	\item К которым были обращения в последнее время, но не было модификаций.
	\item К которым были и обращения, и модификации в последнее время.
\end{enumerate}

Для замещения выбирается произвольная страница из самого низкого непустого класса.

\subsection{Алгоритм FIFO и его модификации}

Система ведет список всех страниц, находящихся в памяти в данный момент.
Недавно поступившие страницы находятся в конце
списка, а те, что поступили раньше всех, находятся в начале. 
Если возникает ошибка отсутствия страницы, удаляется страница из начала списка, и в конец добавляется новая страница.

Алгоритм второй шанс является простой модификацией алгоритма FIFO и решает проблему удаления часто востребуемой страницы.
Для этого используется проверка бита R самой старой страницы. 
Если значение этого бита равно нулю, то это означает, что страница не только старая, но и невостребованная, поэтому она сразу же удаляется.
Если бит R имеет значение 1, то он сбрасывается, а страница помещается в конец списка страниц, а время ее загрузки обновляется, как будто она только что поступила в память.
Затем поиск продолжается.

Алгоритм часы является улучшением алгоритма второй шанс.
Он основан на идее использования циклического списка страниц, представленного в виде часов, где стрелка указывает на самую старую страницу.

Принцип работы алгоритма часы следующий:
\begin{enumerate}
	\item В начале работы алгоритма все страницы помещаются в циклический список в виде часов, где каждая страница имеет бит R, который указывает на ее актуальность.
	\item При возникновении ошибки отсутствия страницы проверяется страница, на которую указывает стрелка в циклическом списке.
	\item Если бит R этой страницы равен 0, она удаляется из памяти, на ее место загружается новая страница, и стрелка сдвигается вперед на одну позицию.
	\item Если бит R равен 1, он сбрасывается, и стрелка перемещается на следующую страницу в списке.
	\item Этот процесс повторяется до тех пор, пока не будет найдена страница с битом R = 0.
\end{enumerate}

\subsection{LRU}

Алгоритм замещения наименее востребованной страницы основан на идее, что страницы, которые долгое время не были востребованы, скорее всего, останутся невостребованными, в то время как страницы, которые интенсивно использовались в последнее время, вероятно будут снова востребованы.
Поэтому стратегия замещения страниц в этом алгоритме основана на выборе наименее востребованной страницы для удаления.

Для реализации алгоритма Least Recently Used каждая страница в памяти связывается с программным счетчиком, который имеет начальное значение 0.
При каждом прерывании от таймера операционная система сканирует все страницы в памяти. 
Для каждой страницы к счетчику добавляется значение бита R,
который равен 0 или 1. 
Таким образом, счетчики позволяют приблизительно отслеживать частоту обращений к каждой странице.

При возникновении ошибки отсутствия страницы для замещения выбирается та страница, у которой счетчик имеет наименьшее значение, то есть та страница, которая дольше всего не была востребована.

Основная проблема этого алгоритма заключается в том, что он никогда не сбрасывает счетчики и страницы, которые активно использовались в прошлом, и сейчас не востребованы все равное будут оставаться в памяти.

Для борьбы с этой проблемой существует алгоритм старения, который предлагает при каждом прерывании таймера не прибавлять 1 к счетчику, а делать сдвиг вправо и прибавлять 1 к левому биту счетчика.

\subsection{Алгоритм рабочий набор}

Процессы начинают работу без каких-либо страниц в памяти,
что приводит к ошибкам отсутствия страниц при первом обращении к данным.
Система загружает страницы по мере необходимости.
Постепенно процесс получает большинство необходимых ему страниц и начинает работу более стабильно.
Рабочий набор страниц, используемых процессом в данный
момент, важен для эффективной работы. 
Многие системы замещения страниц стремятся отслеживать рабочий набор каждого процесса и обеспечивать его присутствие в памяти, перед перезапуском процесса.

Для реализации модели рабочего набора необходимо, чтобы система отслеживала, какие страницы именно входят в рабочий набор.
Имея эту информацию, можно использовать следующий алгоритм замещения страниц: при возникновении ошибки отсутствия страницы следует выселить ту страницу, которая не принадлежит рабочему набору.

Рабочий набор представляет собой набор страниц, используемых в k последних обращениях к памяти. 
Для реализации алгоритма можно отслеживать страницы, использованные в k последних миллисекундах выполнения, вместо поиска страниц, используемых в k последних обращениях.
Для получения этой информации можно добавить специальное поле в таблицу страниц и обновлять его на основе бита R по тику таймера.

Если возраст страницы превышает заранее выбранное значение на момент возникновения ошибки, она становится кандидатом на замену. 
В противном случае удаляется страница с самым большим возрастом или случайная, если у всех страниц одинаковый параметр.

\subsection{Алгоритм WSClock}

Алгоритм WSClock (Working Set Clock) является модификацией алгоритма рабочего набора и базируется на структуре данных, аналогичной циклическому списку страничных блоков, используемой в алгоритме часы.

Основные принципы работы данного алгоритма следующие:
\begin{enumerate}
	\item Создается пустой циклический список страничных блоков.
	\item При загрузке первой страницы она добавляется список. По мере загрузки следующих страниц они также попадают в список, формируя замкнутое кольцо.
	\item В каждой записи списка содержится поле времени последнего использования из базового алгоритма рабочего набора, а также биты R и M.
	\item При возникновении ошибки отсутствия страницы сначала проверяется	страница, на которую указывает стрелка в списке. Если бит R установлен в 1, это означает, что страница была использована в течение	текущего такта и не является идеальным кандидатом на удаление.
	\item Затем бит R устанавливается в 0, стрелка перемещается на следующую страницу в списке, и процесс повторяется уже для нее.
	\item После того, как бит R у страницы, на которую указывает стрелка, 	равен 0 и ее возраст превышает заданное значение, а также страница не изменена, происходит замещение этой страницы.
	\item Если страница была изменена, то планируется запись на диск.
\end{enumerate}

Если стрелка проходит полный круг и хотя бы одна запись на диск запланирована, поиск может продолжаться до тех пор, пока не будет найдена неизмененная страница.
В противном случае все страницы считаются частью рабочего набора, и замещается любая страница, которая не была изменена.
Если такой страницы нет, то замещается текущая страница.

\subsection{Сравнительный анализ методов замещения страниц}

Оптимальный алгоритм удаляет страницу с самым отдаленным предстоящим обращением. 
На практике реализовать такой алгоритм невозможно, но его можно использовать в качестве оценочного критерия.

Алгоритм исключения недавно использовавшейся страницы проводит разбиение всех страниц, основываясь на состоянии битов M и R, на 4 класса и проводит замещение произвольной страницы наименьшего непустого класса.

Алгоритм FIFO работает по принципу очереди и удаляет самую старую страницу.
Алгоритм второй шанс борется с недостатками FIFO и перед удалением страницы проверяет не используется ли она в данный момент.
Алгоритм часы является разновидностью алгоритма второй шанс, но требует меньше времени на выполнение.

Алгоритм замещения наименее востребованной страницы стремится удалять страницы, которые не были востребованы долгое время. 
У этого алгоритма есть недостаток, связанный с тем, что страница, которая активно использовалась в прошлом, не обязательно будет востребована сейчас. 
Для борьбы с этим недостатком был разработан алгоритм старения.

Алгоритм рабочего набора отслеживает набор страниц, используемых за определенный промежуток времени и замещает страницу, которая не относится к рабочему набору.
Алгоритм WSClock является оптимизацией алгоритма рабочего набора.

На практике чаще всего используются алгоритм старения и WSClock.
Оба обеспечивают неплохую производительность страничной организации памяти и могут быть эффективно реализованы, но не лишены недостатков на определенном наборе задач.

\section{Нейронные сети}\label{sec:neuro_net}
Модель нейронной сети основана на биологическом нейроне.
У нейрона есть ядро, которое называется телом. 
В теле накапливается электрический заряд.
С телом соединены отростки.
Отростки, по которым сигнал поступает в тело, называются дендритами. 
Отросток, по которому сигнал передается другим нейронам, называется аксоном. 
Место, где аксон соединяется с дендритами, называется синапсом. 
Синапс отвечает за количество заряда, которое перейдет от аксона к дендриту. 
Синапс может изменяться со временем. 
Именно с настройкой синапса и связана тренировка биологической нейронной сети.

\textbf{Математическая модель МакКаллока-Питтса.}
В математической модели МакКаллока-Питтса, тело нейрона, где накапливается заряд, заменяется на сумматор. 
Дендриты являются входами сумматора, а выходом -- аксоном. 
Биологический нейрон накапливает заряд до тех пор, пока этот заряд не достигнет какого-то значения, и только после этого этот заряд уходит по аксону к другим нейронам. 
В математической модели к сигналу после выхода из сумматора применяется функция активации и только после этого сигнал попадает на дендрит следующего нейрона. 
Синапсы в математической модели заменяются на веса входов нейрона. 
Математическая модель нейрона выражается зависимостью~(\ref{formula:math_neuro})
\begin{equation}\label{formula:math_neuro}
y = f\left(\sum\limits_{i = 1}^{n}(w_{\rm{i}}x_{\rm{i}}) + b\right),
\end{equation}
где $y$ -- сигнал на выходе из нейрона, $f$ -- функция активации, $w_{\rm{i}}$ -- вес i входа, $x_{\rm{i}}$ -- сигнал этого входа, $b$ -- некоторое значение смещения, которое задается отдельно для каждого нейрона.
Обучение нейронной сети происходит за счет настройки синаптических весов $w_{\rm{i}}$ и смещения $b$.

\textbf{Функции активации.}
Существует много различных функций активации.
Наиболее популярными считаются логистическую функцию, гиперболический тангенс, ReLU~\cite{activation_function}. Важной особенностью функций активации является их дифференцируемость, поскольку при обратном распространении ошибки необходимо вычислять градиенты, использующие производную функции активации.

Логистическая функция преобразовывает поступающие в неё значения в вещественный диапазон [0, 1]. 
Это означает, что при x>0 выходное значение будет примерно равно единице, а при x<0 будет близким к нулю. 
Данная функция часто используется в задачах классификации~\cite{activation_function}. 
Логистическая функция определяется зависимостью~(\ref{formula:log_function}).
\begin{equation}\label{formula:log_function}
y = \frac{1}{1 + e^{-x}}.
\end{equation}

Гиперболический тангенс схож с логистической функцией, но в отличии от нее может принимать отрицательные значения. 
Гиперболический тангенс определяется зависимостью~(\ref{formula:tanh}).
\begin{equation}\label{formula:tanh}
y = \frac{e^{2x} - 1}{e^{2x} + 1}.
\end{equation}

Функция ReLU возвращает 0, если принимает отрицательный аргумент, в случае же положительного аргумента, функция возвращает само число. 
Функция ReLU определяется зависимостью~(\ref{formula:relu})
\begin{equation}\label{formula:relu}
\mathrm{ReLU}(x)=\begin{cases}
x, & \text{если}\ x>0, \\
0, & \text{иначе}.
\end{cases}
\end{equation} 

ReLU решает проблему обнуления градиента (ситуация, при которой во время обучения градиенты по всем весам становятся близкими или равными нулю) для положительных чисел, также она вычисляется гораздо проще, чем сигмоидальные функции (логистическая функция, гиперболический тангенс)~\cite{activation_function}.

\textbf{Составляющие нейронной сети.}
При обучении нейронной сети используются две подвыборки обучающего множества.
Вся обучающая выборка состоит из какого-то количества объектов, для которых известны признаки, на которые должна обучиться нейронная сеть. 
Первая подвыборка называется тренировочной и используется для итеративного обучения нейронной сети. 
Вторая называется тестовой и используется для оценки того, насколько хорошо обучена нейронная сеть.

Нейронную сеть определяют следующие параметры:
\begin{itemize}
	\item архитектура нейронной сети -- отвечает за то, как нейроны связаны между собой;
	\item функция потерь -- определяет насколько точно работает модель~\cite{neuro_base};
	\item метод оптимизации -- определяет способ уменьшения функции потерь на каждой итерации обучения.
\end{itemize}

Нейроны делятся на три типа: входной, скрытый и выходной. 
В том случае, когда нейросеть состоит из большого количества нейронов, вводят термин слоя. 
Соответственно, есть входной слой, который получает информацию, некоторое количество скрытых, которые ее обрабатывают и выходной слой, который выводит результат~\cite{neuro_architecture}. 
Количество скрытых слоев и число нейронов в каждом из них задают архитектуру нейронной сети.

\textbf{Методы оптимизации.}
Один из методов оптимизации -- градиентный спуск~\cite{gradient}. 
Градиентный спуск основан на пошаговом приближении функции к локальному минимуму. 
На каждой итерации алгоритма новые значения получаются по формуле~(\ref{formula:gradient})
\begin{equation}\label{formula:gradient}
w_{\rm{1}} = w_{\rm{0}} - \alpha\Delta f(w_{\rm{0}}),
\end{equation}
где $w_{\rm{1}}$ -- вектор новых значений, которые подбираются алгоритмом, $w_{\rm{0}}$ -- значения параметров на текущем шаге, $\Delta f(w_{\rm{0}})$ -- вектор градиентов функции потерь по каждому из параметров на текущем шаге, $\alpha$ -- скорость обучения. 

На каждой итерации градиентного спуска требуется считать градиент функции потерь, которая зависит от функций активации каждого из нейронов сети. 
В связи с этим к фукнциям потерь и активации применяются требования по дифференцируемости.

В связи с тем, что градиентный спуск находит только локальный минимум, не всегда полученный результат будет оптимальным. 
Результат работы алгоритма зависит от изначальных настроек параметров нейронной сети.

Выделяют три основных типа градиентного спуска~\cite{gradient}:
\begin{itemize}
	\item мини-пакетный градиентный спуск -- в этом случае обучающий набор данных разбивается на небольшие партии, которые используются для расчета ошибки модели и обновления коэффициентов модели;
	\item стохастический градиентный спуск -- в этом случае градиент оптимизируемой функции считается на каждом шаге не как сумма градиентов от каждого элемента выборки, а как градиент от одного, случайно выбранного элемента;
	\item пакетный градиентный спуск -- это разновидность
	алгоритма градиентного спуска, который вычисляет ошибку для	каждого примера в наборе обучающих данных, но обновляет модель только после того, как все обучающие примеры были оценены.
\end{itemize}

Одной из проблем градиентного спуска является неизменяемая во время обучения скорость обучения. 
Постоянная скорость обучения может привести к следующим проблемам: если ее значение будет выбрано слишком низким, то модель будет дольше сходиться и требовать большего числа итераций для достижения оптимального решения, если ее значение будет слишком большим, то модель может расходиться и на каждой итерации проходить мимо глобального минимума.

Для решения этой проблемы нужно использовать адаптивно настраивающуюся скорость обучения.
Значение скорости обучения для каждого параметра должно настраиваться адаптивно, исходя из правила, что чем больше значение ошибки, тем больше должна быть скорость обучения. 
Увеличение скорости обучения при больших значениях ошибки дает возможность перескочить через локальные минимумы, а ее уменьшение при малых значениях не дает модели на каждой итерации перескакивать через глобальный минимум.

Для адаптивного изменения весов модели можно использовать алгоритм RMSProps. Этот алгоритм работает по следующим правилам:
\begin{itemize}
	\item на каждой итерации для каждого параметра считается экспоненциальное скользящее среднее градиента с учетом всей истории обучения;
	\item при помощи полученных значений для каждого параметра вычисляется скорость обучения и производится обновление весов модели.
\end{itemize}

Экспоненциальное скользящее среднее на очередной итерации высчитывается по формуле~(\ref{formula:rmsprops_ema})
\begin{equation}\label{formula:rmsprops_ema}
	E_{\rm{t}} = \beta * g_{\rm{t}}^2 + (1 - \beta) * E_{\rm{t-1}},
\end{equation}
где $E_{\rm{t}}$ -- новое полученное значение экспоненциального скользящего среднего, $E_{\rm{t-1}}$ -- значение, полученное на предыдущей итерации, $\beta$ -- настраиваемый коэффициент, $g_{\rm{t}}$ -- градиент функции потерь по соответствующему параметру.

После этого веса обновляются с использованием соотношения~(\ref{formula:rmsprops_w})
\begin{equation}\label{formula:rmsprops_w}
	w_{\rm{t}} = w_{\rm{t-1}} - \frac{\eta}{\sqrt{E_{\rm{t}}}}g,
\end{equation}
где $w_{\rm{t}}$ -- новое полученное значение параметра модели, $w_{\rm{t-1}}$ -- предыдущее значение этого параметра, $\eta$ -- скорость обучения, $E_{\rm{t}}$ -- значение экспоненциального скользящего среднего для этого параметра.

Для улучшения сходимости модели при адаптивном обновлении скорости обучения можно считать экспоненциальное скользящее среднее не только по квадрату градиента, но и по самому значению и использовать оба полученных значения при подсчете новой скорости обучения на каждой итерации. 
Такой подход реализован в алгоритме Adam~\cite{zhang2024transformers}.

Первый и второй моменты высчитываются по формулам~(\ref{formula:adamema1}) и~(\ref{formula:adamema2}) соответственно

\begin{equation}\label{formula:adamema1}
	m_{\rm{t}} = \beta_{\rm{1}} * g_{\rm{t}} + (1 - \beta_{\rm{1}}) * m_{\rm{t-1}},
\end{equation}

\begin{equation}\label{formula:adamema2}
	v_{\rm{t}} = \beta_{\rm{2}} * g_{\rm{t}}^2 + (1 - \beta_{\rm{2}}) * v_{\rm{t-1}},
\end{equation}
где $m_{\rm{t}}$ и $v_{\rm{t}}$ -- первый и второй моменты в соответствующий момент времени, $\beta_{\rm{1}}$ и $\beta_{\rm{2}}$ -- настраиваемые коэффициента, $g$ -- градиент функции потерь по соответствующему параметру.

Для увеличения влияния истинных значений градиента на начальных этапах к моментам применяется корректировка по формулам~(\ref{formula:adamcorr1}) и~(\ref{formula:adamcorr2})

\begin{equation}\label{formula:adamcorr1}
	\hat{m_{\rm{t}}} = \frac{m_{\rm{t}}}{1 - \beta_{\rm{1}}^t},
\end{equation}

\begin{equation}\label{formula:adamcorr2}
	\hat{v_{\rm{t}}} = \frac{v_{\rm{t}}}{1 - \beta_{\rm{2}}^t}.
\end{equation}

Итоговое обновление весов осуществляется по формуле 
(\ref{formula:adam_w})
\begin{equation}\label{formula:adam_w}
	w_{\rm{t}} = w_{\rm{t-1}} - \eta\frac{\hat{m_{\rm{t}}}}{\sqrt{\hat{v_{\rm{t}}}} + \epsilon},
\end{equation}
где $w_{\rm{t}}$ -- новое полученной значение параметра модели, $w_{\rm{t-1}}$ -- предыдущее значение этого параметра, $\eta$ -- скорость обучения, $\epsilon$ -- поправка, защищающая от деления на ноль.

\textbf{Функции потерь.}
Согласно исследованиям~\cite{loss_function} для задачи классификации самой эффективной функцией потерь являются категориальная перекрестная энтропия, которая определяется выражением~(\ref{formula:soft_max1})
\begin{equation}\label{formula:soft_max1}
C\!M = - \sum\limits_{i = 1}^{N}t_{\rm{i}}\log{p_{\rm{i}}},
\end{equation}
где $N$ -- число классов классификации, $t_{\rm{i}}$ -- 0 или 1 в зависимости от того принадлежит ли изображение на входе нейронной сети классу, за который отвечает $i$ нейрон выходного слоя, $p_{\rm{i}}$ -- результат на выходе из нейрона.

В задачах классификации используют категориальную перекрестную энтропию в качестве функции потерь. 
В таком случае на выходном слое нейронной сети создается столько нейронов, сколько возможных классов может иметь объект на входе.
В качестве функции активации для каждого из таких нейронов используют софт макс. 
Софт макс определяется выражением~(\ref{formula:soft_max})
\begin{equation}\label{formula:soft_max}
S\!M_{\rm{i}} = \frac{e^{y_{\rm{i}}}}{\sum\limits_{i = 1}^{N}e^{y_{\rm{j}}}},
\end{equation}
где $y_{\rm{i}}$ -- результат на выходе из нейрона, к которому применяется функция активации, $N$ -- число нейронов в выходном слое, $y_{\rm{j}}$ -- результат на выходе из $j$ нейрона выходного слоя.

Знаменатель в выражении~(\ref{formula:soft_max}) отвечает за нормировку. 
Таким образом, каждый из нейронов выходного слоя показывает вероятность принадлежности объекта на входе нейронной сети к некоторому классу, а сумма всех этих вероятностей будет равна 1.

\section{Многослойные сети}
\subsection{Перцептрон}
Перцептрон -- это математическая модель, воспроизводящая принципы обработки информации, схожие с работой человеческого головного мозга. Архитектура перецептрона состоит из трех ключевых элементов~\cite{mfetoum2024multilayer}:
\begin{itemize}
	\item сенсоры -- получают входные сигналы;
	\item ассоциативные элементы -- обрабатывают данные;
	\item реагирующие элементы -- формирует итоговый отклик.
\end{itemize}

Эти компоненты организованы в слои нейронной сети: входной, один или несколько скрытых и выходной.
Схема трехслойного перцептрона приведена на рисунке~\ref{img:perceptron}
\includeimage
{perceptron} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.8\textwidth} % Ширина рисунка
{Схема перцептрона} % Подпись рисунка

$W_{nm}$ и $W_{mk}$ на схеме -- матрицы обучаемых весов. $n$, $m$, $k$ -- число нейронов на входном, скрытом и выходном слоях соответственно. 

Результат на выходе из k-го нейрона выходного слоя может быть посчитан по следующей формуле~(\ref{formula:perceptron})
\begin{equation}\label{formula:perceptron}
	Y_k(x) = Y_k(x_1, x_2, ..., x_n) = f_2(\sum_{j=0}^{m}(w_{jk} f_1(\sum_{i=0}^{n}(w_{ij}x_i))),
\end{equation}
где $f_1$ и $f_2$ -- функции активации на скрытом и выходном слоях соответственно, $w_{ij}$ и $w_{jk}$ -- обучаемые веса из матриц $W_{nm}$ и $W_{mk}$.

В многослойном перцептроне данные последовательно проходят через входной слой, скрытый и выходной.
На каждом этапе нейроны слоя выполняют следующие действия:
\begin{itemize}
	\item линейная комбинация -- нейрон умножает сигналы на соответствующие веса и суммирует результаты;
	\item нелинейное преобразование -- полученная сумма пропускается через активационную функцию, которая усиливает характеристики, за которые отвечает соответствующий узел.
\end{itemize}

Марвин Минский и Сеймур Паперт в своей работе~\cite{minsky1969perceptrons} показали, что однослойные нейронные сети, включающие только входной и выходной слои, способны работать исключительно с линейно разделимыми задачами и обеспечивают лишь линейную аппроксимацию.
Этот барьер преодолевается за счёт внедрения скрытых слоёв.

В таких сетях скрытый слой играет ключевую роль: входные данные трансформируются в новое пространство, где выходной слой строит разделяющие поверхности для классификации.
Таким образом, модель не только анализирует исходные признаки, но и выявляет признаки признаков, формируемые скрытыми нейронами. 
Это позволяет сети обучаться сложным нелинейным закономерностям.

Число нейронов на входном слое напрямую зависит от числа входных признаков.
Число нейронов на выходном слое зависит от решаемой задачи.
Для задач классификации это число равно числу возможных классов и каждый нейрон на выходном слое отвечает за вероятность принадлежности входного параметра одному из классов.

Число нейронов на скрытом слое, как правило, выбирается опытным путем.
Слишком большое число нейронов может привести к переобучению модели, а слишком маленькое может не хватить для решения поставленной задачи.

Хехт-Нильсен в своей работе~\cite{hecht1987}, основанной на работе Колмогорова~\cite{kolmogorov1957} предлагает использовать $2N + 1$ нейронов на скрытом слое, где $N$ -- число входов сети.

Баум и Хесслер с своей работе~\cite{baum1989} вводят эмпирическое правило для числа весов на скрытом слое для борьбы с переобучением~(\ref{formula:baum})
\begin{equation}\label{formula:baum}
	p > \frac{w}{\varepsilon},
\end{equation}
где $p$ -- размер обучающей выборки, $w$ -- число весов, $\varepsilon$ -- допустимый уровень ошибки.

Для обучения перцептрона могут быть использованы следующие методы:
\begin{itemize}
	\item стохастические методы обучения;
	\item обратное распространение ошибки.
\end{itemize}

Стохастические методы обучения предполагают обучение по следующему алгоритму:
\begin{enumerate}
	\item Выбрать значения весов случайным образом.
	\item Подсчитать значение функции потерь.
	\item Подкорректировать значение случайного весового коэффициента на небольшую величину. Если коррекция уменьшает значение функции потерь, то оставить ее, иначе вернуться к изначальному состоянию.
	\item Повторять шаг 3 до тех пор, пока сеть не будет достаточно обучена.
\end{enumerate}

Для реализации обратного распространения ошибки необходимо осуществить минимизацию функции потерь с помощью изменения значений обучаемых весов в направлении обратном градиенту.
Для расчета частной производной по каждому из весов необходимо выразить функцию потерь через значения весов и входных аргументов.
Для того, чтобы выразить значение на выходе из k-го нейрона через обучаемые веса и входные параметры можно использовать формулу~(\ref{formula:perceptron}).

\subsection{RBF сеть}
RBF сеть является многослойным перцептроном, на скрытом слое которого используются RBF нейроны~\cite{jiang2022efficient}.
Потенциал такого нейрона рассчитывается как евклидово расстояние между векторами весовых коэффициентов и входных величин~(\ref{formula:rbf_neuro}):
\begin{equation}\label{formula:rbf_neuro}
	V = ||w - x|| = \sqrt{\sum_{i=1}^{N}(w_i-x_i)^2},
\end{equation}
где $w$ -- вектор весовых коэффициентов, $x$ -- вектор входных величин, а $N$ -- размер этих векторов.

Для RBF нейронов используется следующая функция активации~(\ref{formula:rbf_act}):
\begin{equation}\label{formula:rbf_act}
	f(V) = e^{-(\frac{V}{b})^2},
\end{equation}
где $V$ -- потенциал нейрона, $b$ -- коэффициент разброса, который отвечает за плавность функции.

Схема RBF сети приведена на рисунке~\ref{img:rbf}
\includeimage
{rbf} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.8\textwidth} % Ширина рисунка
{Схема RBF сети} % Подпись рисунка

На схеме буквой R обозначены RBF нейроны. $W_{nm}$ -- матрица обучаемых весов скрытого слоя, $W_m$ -- вектор обучаемых весов выходного слоя, $n$ -- число нейронов на входном слое, $m$ -- число RBF нейронов.
Выходной слой является линейной комбинацией активаций RBF нейронов скрытого слоя.

Особенностью такой сети является то, что каждый RBF нейрон активируется только тогда, когда входные данные близки к его эталонному вектору весов $w$.
Таким образом, каждый нейрон скрытого слоя представляет собой центр кластера в пространстве данных, а параметр $b$ отвечает за область охвата этого нейрона.
Чем больше значение $b$, тем большое отклонение от вектора эталонных весов будет приводить к активации нейрона.

Обучение RBF сети состоит из трех этапов:
\begin{itemize}
	\item выбор центров кластеров;
	\item расчет параметра разброса $b$;
	\item обучения весов выходного слоя.
\end{itemize}

Для выбора центров кластеров могут быть использованы методы кластеризации, к примеру, k-средний.

Параметр разброса может быть как настроен вручную для каждого кластера, так и задан константой для всех нейронов.
К примеру, параметр $b$ может быть задан как среднее расстояние между центрами кластеров.

Для обучения весов выходного слоя может быть использована линейная регрессия.

\subsection{Вероятностная сеть}
Вероятностная модель является развитием RBF сети. Схема такой модели представлена на рисунке~\ref{img:pnn}
\includeimage
{pnn} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.8\textwidth} % Ширина рисунка
{Схема вероятностной сети} % Подпись рисунка 

Вероятностная сеть состоит из следующих слоев:
\begin{itemize}
	\item входной слой;
	\item слой образцов;
	\item суммирующий слой;
	\item выходной слой.
\end{itemize}

Входной слой -- первый этап работы сети, который принимает входные данные.
Каждый нейрон на этом слое соответствует одному входному признаку.

Каждый нейрон на слое образцов соответствует одному образцу из обучающей выборки.
Нейроны этого слоя используют RBF функцию активации для вычисления сходства между входным набором данных и образцом, которому они соответствуют.

Каждый нейрон на слое суммирования представляет класс.
Нейроны этого слоя суммируют активации RBF нейронов с предыдущего слоя, которые относятся к одному классу.

Выходной слой принимает решение о классификации входных данных, выбирая класс с наибольшей вероятностью.

\section{Рекуррентные сети}
Рекуррентные нейронные сети -- нейронные сети с обратной связью между различными слоями нейронов.
Их характерная особенность -- передача сигналов с выходного или скрытого слоя во входной слой.
Рекуррентная нейронная сеть может состоять из любого числа слоев.

Рекуррентные нейронные сети хорошо подходят для обработки последовательностей, например, временные ряды (изменения цен акций, показания датчиков), последовательности с зависимыми элементами (предложения естественного языка), то есть любые данные, где соседние экземпляры (точки выборки) зависят друг от друга и эту зависимость нельзя игнорировать~\cite{дель2021прогноз}.

Общая схема рекуррентной сети приведена на рисунке~\ref{img:rnn}.
\includeimage
{rnn} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.95\textwidth} % Ширина рисунка
{Схема рекуррентной сети} % Подпись рисунка 

Фрагмент нейронной сети А принимает входное значение $x_i$ и возвращает значение $h_i$. 
Наличие обратной связи позволяет передавать информацию от одного шага сети к другому. 
Рекуррентную сеть можно рассматривать, как несколько копий одной и той же сети, каждая из которых передает информацию последующей копии.

\subsection{Нейронная сеть Хопфилда}
Схема нейронной сети Хопфилда из трех нейронов изображена на рисунке~\ref{img:hopfield}.
\includeimage
{hopfield} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.95\textwidth} % Ширина рисунка
{Схема нейронной сети Хопфилда} % Подпись рисунка 

Нейронная сеть Хопфилда -- полносвязная однослойная нейронная сеть с симметричной матрицей связей~\cite{ромасенко2022запоминание}.
Функционирование сети продолжается до тех пор, пока не будет достигнуто состояние равновесия, то есть до тех пор, пока новый выход из сети не будет равен предыдущему.
Входной образ является начальным состоянием сети, а при равновесии получается выходной.

Сеть состоит из $N$ нейронов, где $N$ -- размерность входного и выходного векторов.
Каждый нейрон на входе и выходе может принимать одно из двух состояний~(\ref{formula:hopfield_neuro}):
\begin{equation}\label{formula:hopfield_neuro}
	x_i^{(t)}, y_i^{(t)} \in \{-1; +1\},
\end{equation}
где $x_i^{(t)}$ и $y_i^{(t)}$ -- значение на входе и выходе i-го нейрона соответственно в момент времени $t$.

Работа сети описывается функцией энергии~(\ref{formula:hopfield_energy}):
\begin{equation}\label{formula:hopfield_energy}
	E = -\frac{1}{2}\sum\limits_{i=1}^{N}\sum\limits_{j=1,j\neq i}^{N}w{ij}x_i x_j,
\end{equation}
где $w_{ij}$ -- элемент матрицы взаимодействия $W$, которая состоит из весовых коэффициентов.
В процессе функционирования сети функция энергии должна монотонно уменьшаться.

Состояние сети определяется множеством текущих выходных сигналов $y_i$ от всех нейронов.
Таким образом, состояние сети является двоичным числом, так как на выходе нейрона может быть только 2 значения.
Каждый бит соответствует значению на выходе конкретного нейрона.

Процесс обучения сети заключается в составлении матрицы взаимодействия $W$.
Матрица строится из $m$ эталонных образов.
Каждый образ является бинарным вектором размерности $N$.

Для расчета весовых коэффициентов применяется следующее выражение~(\ref{formula:hopfield_weights}):
\begin{equation}\label{formula:hopfield_weights}
	w_{ij} = \frac{1}{N}\sum\limits_{d=1}^{m}X_{id}X_{jd},
\end{equation}
где $N$ -- размерность векторов, $m$ -- число запоминаемых выходных векторов, $d$ -- индекс запоминаемого выходного вектора, $X_{ij}$ -- i-я компонента запоминаемого выходного j-го вектора.
Матрица взаимодействий является симметричной.
Элементы на главной диагонали матрицы равны нулю.

Значение выхода i-го нейрона в текущий момент рассчитывается по следующей формуле~(\ref{formula:hopfield_state}):
\begin{equation}\label{formula:hopfield_state}
	y_i^{(t)} = sign(\sum\limits_{j=1, j \neq i}^{N}w_{ji}y_j^{(t-1)}),
\end{equation}
где $sign$ -- функция, возвращающая знак аргумента.

Существует два режима работы сети Хопфилда:
\begin{enumerate}
	\item Синхронный режим. При таком подходе все нейроны просматриваются последовательно, их состояния запоминаются и не меняются до тех пор, пока не будут обработаны все нейроны. Затем состояние всех нейронов синхронно обновляется.
	\item Асинхронный режим. При таком режиме работы состояния нейронов обновляются последовательно, то есть для каждого нейрона поочередно вычисляется новое состояние, для каждого следующего нейрона новое состояние вычисляется с учетом всех изменений состояний рассмотренных ранее нейронов.
\end{enumerate}

В асинхронном режиме работы невозможен динамический аттрактор, то есть вне зависимости от количества запомненных образов и начального состояния сеть придет к устойчивому состоянию.

На число образов, которые может запомнить сеть Хопфилда, накладывается ограничение~(\ref{formula:hopfield_samples}):
\begin{equation}\label{formula:hopfield_samples}
	M < \frac{N}{2\log_2N},
\end{equation}
где $M$ -- максимально число эталонов, которое может запомнить сеть, $N$ -- число нейронов.

Одним из недостатков сети является проблема ложных аттракторов: достижение устойчивого состояния сети не гарантирует правильный ответ.

\subsection{Двунаправленная ассоциативная память}
Двунаправленная ассоциативная память является расширением сети Хопфилда~\cite{бахтин2024интеллектуальные}.
Эта сеть позволяет ассоциировать пары векторов.
Схема сети представлена на рисунке~\ref{img:bam}.
\includeimage
{bam} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.95\textwidth} % Ширина рисунка
{Двунаправленная ассоциативная память} % Подпись рисунка 

Сеть состоит из двух слоев.
Входной вектор А поступает на слой А и обрабатывается матрицей весов $W$ сети.
В результате вырабатывается выходной вектор B, который поступает на слой B.
Вектор B обрабатывается транспонированной матрицей $W^T$.
В результате работы этого слоя получается новый входной вектор A.
Такой процесс функционирования сети продолжается до тех пор пока, не будет достигнуто стабильное состояние, при котором ни вектор A, ни вектор B не изменяются.

Обучение сети происходит с помощью обучающего набора, состоящего из пар векторов A и B.
Матрица весов вычисляется как сумма произведений всех векторных пар обучающего набора~(\ref{formula:bam_weights}):
\begin{equation}\label{formula:bam_weights}
	W = \sum\limits_{i=1}^{M}{A_i}^T B_i,
\end{equation}
где $W$ -- матрица весов, $M$ -- число обучающих пар, $A_i$ и $B_i$ -- вектора из обучающего набора.

\subsection{Сеть Элмана}
Нейронная сеть Элмана является рекуррентной нейронной сетью со слоем контекста, который позволяет учитывать предыдущее состояние при обработке текущего входа.

Сеть состоит из трех слоев. схема сети Элмана изображена на рисунке~\ref{img:elmann}.
\includeimage
{elmann} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.8\textwidth} % Ширина рисунка
{Схема сети Элмана} % Подпись рисунка 

Входной слой принимает текущий элемент последовательности $x_t$ размерности $i$.

Скрытый слой вычисляет состояние $h_t$ на основе текущего входа $x_t$ и состояния контекстного слоя $c_t$, которое является копией состояния скрытого слоя с предыдущего шага $h_{t-1}$.
Состояние скрытого слоя вычисляется с помощью выражения~(\ref{formula:elman_hidden}):
\begin{equation}\label{formula:elman_hidden}
	h_t = f_h(W_{ih} * x_t + W_{hh} * c_t + b_h),
\end{equation}
где $W_{ih}$ -- веса между входом и скрытым слоем, $W_hh$ --  веса между скрытым слоем на предыдущем шаге и скрытым слоем на текущем шаге, $b_h$ -- смещения на скрытом слое, $f_h$ -- функция активации скрытого слоя.

Выходной слой вычисляет результат работы сети $y_t$ на основе состояния скрытого слоя.
Работа выходного слоя описывается выражением~(\ref{formula:elman_out}):
\begin{equation}\label{formula:elman_out}
	y_t = f_o(W_{ho} * h_t + b_o),
\end{equation}
где $W_{ho}$ -- веса между скрытым и выходным слоем, $b_o$ -- смещение выходного слоя, $f_o$ -- функция активации на выходном слое.

\subsection{Сеть LSTM}
Сеть LSTM~\cite{yu2019review} состоит из четырех компонентов:
\begin{itemize}
	\item состояние ячейки -- память сети, которая передается по всей цепочке модулей;
	\item фильтр забывания -- контролирует меру сохранения информации в ячейке;
	\item входной фильтр -- контролирует меру вхождения нового значения в память;
	\item выходной фильтр -- отвечает за меру того, как будет использовано значение из ячейки памяти при расчете выходной функции активации.
\end{itemize}

Схема LSTM изображена на рисунке~\ref{img:lstm}.
\includeimage
{lstm} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.8\textwidth} % Ширина рисунка
{Схема LSTM сети} % Подпись рисунка 

Ключевой из них -- состояние ячейки, которая переходит между повторяющимися модулями сети, подвергаясь преобразованиям.
Три других компонента отвечают за забывание прошлого состояния ячейки, обновление состояния на основе входных данных и выхода из прошлого модуля, а также за получение выходного значения из текущего блока~\cite{al2024rnn}.

Первый компонент нужен для определения того, какую часть информации можно выбросить из состояния ячейки.
На вход к нему поступают входные данные в текущий блок и выходной вектор из прошлого модуля.
На выходе при помощи сигмоидного фильтра для каждого значения в состоянии ячейки вычисляется число от 0 до 1.
Результат работы этого фильтра описывается следующим выражением~(\ref{formula:lstm_forget}):
\begin{equation}\label{formula:lstm_forget}
	f_t = \sigma(W_f[h_{t-1}, x_t] + b_f),
\end{equation}
где $[h_{t-1}, x_t]$ -- конкатенация результата работы предыдущего слоя и входного вектора в текущий слой, $W_f$ и $b_f$ -- матрица и вектор обучаемых весов, $f_t$ -- результат работы фильтра.

Задача следующего компонента -- определить какая новая информация будет сохранена в ячейке.
Для этого сначала при помощи сигмоидного входного фильтра определяются значения, которые будут сохранены в ячейке, а затем с использованием слоя гиперболического тангенса вычисляются новые значения кандидатов на попадание в ячейку.
Работа этого фильтра определяется при помощи выражений~(\ref{formula:lstm_input1}) -~(\ref{formula:lstm_input2}):
\begin{equation}\label{formula:lstm_input1}
	i_t = \sigma(W_i[h_{t-1}, x_t] + b_i),
\end{equation}

\begin{equation}\label{formula:lstm_input2}
	\hat{C_t} = \tanh(W_C[h_{t-1}, x_t] + b_C),
\end{equation}
где $i_t$ определяет, какие значения будут сохранены в ячейке, $\hat{C_t}$ -- новые значения кандидатов на попадание в ячейку, $W_i$, $W_C$, $b_i$, $b_c$ -- матрицы и вектора обучаемых весов.

Обновление состояния ячейки происходит с использованием следующего выражения~(\ref{formula:lstm_state}):
\begin{equation}\label{formula:lstm_state}
	C_t = f_t * C_{t-1} + i_t*\hat{C_t},
\end{equation}
где $C_t$ -- новое состояние ячейки, $C_{t-1}$ -- состояние ячейки на прошлом шаге.

Задача последнего компонента -- определить, какая информация будет на выходе из текущего модуля.
Для этого используется поточечное умножение текущего состояния ячейки, пропущенного через фильтр гиперболического тангенса, и входных данных, объединенных с выходом из прошлого модуля и прошедших через сигмоидный фильтр.
Работа этого компонента определяется выражениями~(\ref{formula:lstm_output1}) -~(\ref{formula:lstm_output2}):
\begin{equation}\label{formula:lstm_output1}
	o_t = \sigma(W_o[h_{t-1}, x_t] + b_o),
\end{equation}

\begin{equation}\label{formula:lstm_output2}
	h_t = o_t * \tanh(C_t),
\end{equation}
где $h_t$ -- результат работы текущего слоя, $C_t$ -- состояние ячейки, $W_o$ и $b_o$ -- матрица и вектор обучаемых весов.


\section{Переобучение нейронной сети}
\subsection{Проблема переобучения нейронной сети}\label{sec:retraining}
Проблема переобучения в нейронных сетях заключается в том, что модель запоминает данные только из обучающей выборки, не обобщая свои знания на новые, ранее не встречавшиеся данные. Это происходит из-за того, что модель адаптируется к обучающим примерам, вместо того, чтобы учиться классифицировать новые данные~\cite{overtraining1}. Признаком переобучения модели является существенно большее значение ошибки распознавания на тренировочной выборке, нежели на тестовой. Зачастую переобучение появляется из-за использования слишком сложных моделей, либо наборов данных, в которых вхождения похожи друг на друга~\cite{overtraining1}.

Недообучение - это противоположная проблема переобучения нейронных сетей. Оно характеризуется тем, что алгоритм обучения не достигает удовлетворительной точности на обучающем множестве. Это может быть связано с тем, что выбрана слишком простая модель или недостаточно обучающих примеров. В результате модель не сможет классифицировать данные в более сложных случаях.~\cite{overtraining1}.

Примеры недообученной, переобученной и оптимально обученной нейронной сети приведены на рисунке~\ref{img:overtraining}.
\includeimage
{overtraining} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{Пример переобучения, недообучения и оптимального обучения} % Подпись рисунка

В этом примере нейронная сеть используется для разделения входного множества объектов на два класса. В первом случае нейронная сеть является недообученной, так как вероятность ошибки равна 0.22 и может быть еще уменьшена за счет использование более сложной формы зависимости.

На примере по середине нейронная сеть строит общую зависимость для данного набора данных, не подгоняя значения под аномальные элементы для рыжего и голубого класса слева и справа соответственно.

Пример справа показывает переобученную нейронную сеть, которая строит зависимость, подгоняя параметры под аномальные параметры обучающей выборки.

Для борьбы с переобучением можно использовать следующие способы:
\begin{itemize}
	\item аугментация обучающей выборки;
	\item метод раннего останова;
	\item регуляризация;
	\item батч нормализация.
\end{itemize}

\subsection{Аугментация}
Первый способ борьбы с переобучением -- аугментация обучающей выборки. Аугментацией называется этап обучения нейронных сетей, состоящий в модификации обучающей выборки. 
В основном этот метод применяется для изображений (поворот, масштабирование, зеркальное отражение и т. д.) по определенному правилу с целью расширить обучающую выборку и повысить ее разнообразие~\cite{augmentation}.

Существует три основных вида аугментации:
\begin{itemize}
	\item геометрическая аугментация -- изменение геометрических параметров изображения, таких как поворот, масштабирование, сдвиг и отражение;
	\item цветовая аугментация -- изменение цветовых параметров изображения, таких как яркость, контрастность и насыщенность;
	\item добавление шума.
\end{itemize}

Аугментация первого типа обычно улучшает качество работы сверточных нейронных сетей, так как такие сети не инвариантны к масштабу, и изменение масштаба изображения значительно повышает разнообразие данных, позволяя сети обучаться на более разнообразных наборах данных~\cite{augmentation}. В статье~\cite{augmentation1} описывается повышение точности распознавания нейронной сети на 10 процентов за счет использования аугментации масштаба.

Аугментации второго типа предполагают случайное изменение компонент R, G, B цвета пикселей изображения. Это один из самых эффективных методов аугментации данных, потому что нейросети без этой аугментации имеют тенденцию к заучиванию правил вида «сумма цветов пикселей в области». Также такая аугментация может улучшить способность распознавания сети при различных условиях освещенности~\cite{augmentation}.

Аугментация добавлением шума на изображение повышает устойчивость модели к шуму на реальных изображениях.

\subsection{Метод раннего останова}
Метод раннего останова после каждой эпохи обучения проверяет точность модели на обучающей и тестовой выборках. Обучение нейронной сети начинается при случайных значениях весов, и с каждой эпохой обучения точность на обучающей выборке будет повышаться, а на тестовой точность сначала будет расти, в момент, когда сеть будет достаточно обучена, зафиксируется на некотором значении, а потом начнет падать из-за переобучения модели.

Суть метода раннего останова заключается в отслеживании точности модели на тестовой выборке и остановке обучения в момент, когда она начинает расти.

К преимуществам данного метода можно отнести:
\begin{itemize}
	\item сокращение времени обучения, так как нейронная сеть не будет обучаться, когда в этом уже нет необходимости;
	\item отсутствие дополнительных затрат на дополнение обучающей выборки.
\end{itemize}

\subsection{Регуляризация}
Метод регуляризации заключается в ограничение значений весовых коэффициентов нейронной сети, что делает их распределение более равномерным. Это достигается за счет добавления некоторого штрафа за увеличение весов нейронной сети в функцию потерь.

Существует три основных вида регуляризации~\cite{regulisation}:
\begin{itemize}
	\item L1 регуляризация, которая также называется Лассо регуляризацией, она добавляет штраф от суммы абсолютных значений весов модели;
	\item L2 регуляризация, которая также называется регуляризацией Тихонова, она добавляет штраф от суммы квадратов весов модели;
	\item дропаут, который случайным образом удаляет связи между нейронами.
\end{itemize}

В пером виде регуляризации новая функция потерь описывается выражением~(\ref{formula:l1reg})
\begin{equation}\label{formula:l1reg}
L_{\rm{new}} = L_{\rm{old}} + \lambda\sum\limits_{i=1}^{N}|w_{\rm{i}}|,
\end{equation}

где $L_{\rm{new}}$ -- новое значение функции потерь, полученное после регуляризации, $L_{\rm{old}}$ -- значение функции потерь до проведения регуляризации, $\lambda$ -- коэффициент штрафования весов, $N$ -- число весов в модели, $w_{\rm{i}}$ -- значение i-го веса модели.

При коэффициенте $\lambda$ равном нулю никакой регуляризации не будет и модель переобучится. При повышении коэффициента штрафования модель будет приближаться к оптимальной, то есть значение ошибки на тестовой выборке будет падать, но чем больше значение этого коэффициента, тем ближе значения всех весов будут к нулю, тем дальше модель отклоняется от локального минимума функции потерь до регуляризации и тем больше растет ошибка модели не тренировочной выборке. Таким образом, значение коэффициента $\lambda$ должно подбираться экспериментально во время обучения. Чем меньше ошибка на тренировочной выборке, тем лучше подобран коэффициент штрафования.

В регуляризации Тихонова штраф считается не по сумме абсолютных значений, а по сумме квадратов и выражается зависимостью~(\ref{formula:l2reg})
\begin{equation}\label{formula:l2reg}
L_{\rm{new}} = L_{\rm{old}} + \lambda\sum\limits_{i=1}^{N}w_{\rm{i}}^2,
\end{equation}
где все параметры аналогичны параметрам в выражении~(\ref{formula:l1reg}).

Главное различие между двумя методам заключается в том, что регуляризация Лассо уменьшает коэффициент менее важной характеристики до нуля, полностью удаляя ее из рассмотрения, а регуляризация Тихонова уменьшает веса, но не делает их равными нулю~\cite{regulisation}.

Еще одним видом регуляризации является дропаут. Суть метода заключается в том, что на каждой итерации обучения нейронной сети все связи между нейронами удаляются с некоторой вероятностью $p$. Иными словами это означает, что на каждой итерации обучения модели значение каждого веса $w_{\rm{i}}$ нейронной сети может быть на одну итерацию приравнено к нулю с некоторой вероятностью $p$.

Таким образом, регуляризация борется с проблемой переобучения нейронной сети и повышает ее обобщающую способность~\cite{regulisation}. К недостатками регуляризации можно отнести то, что:
\begin{itemize}
	\item добавление штрафа или удаление некоторых связей может привести к ухудшению точности модели на обучающих данных;
	\item нельзя заранее оптимальным образом определить коэффициент штрафования весов $\lambda$ и вероятность удаления связи между нейронами $p$.
\end{itemize}

\subsection{Нормализация}\label{sec:normalisation}
Обычно при обучении нейронной сети шаг градиентного спуска делается не по одному конкретному примеру, а сразу по некоторому набору обучающих примеров. Такой подход имеет следующие преимущества~\cite{regulisation}:
\begin{itemize}
	\item усреднение градиента по нескольким примерам представляет собой апроксимацию градиента по всему тренировочному множеству, и чем больше примеров используется в одном мини-батче, тем точнее это приближение, использование всего обучающего множества невозможно в силу ограничений вычислительных ресурсов;
	\item в глубоких нейронный сетях к каждому примеру в отдельности требуется применить большое число последовательных операций, в случае использования некоторого набора обучающей примеров, можно выполнять эти последовательные операции в параллельном режиме для каждого примера в отдельности.
\end{itemize}

При таком подходе к обучению и использовании глубоких нейронных сетей возникает проблема, связанная с тем, что изменение распределения активаций выходов первых слоев на очередном шаге градиентного спуска приводит к сдвигу распределения данных во всех последующих слоях, что затрудняет их обучение и может ухудшить результаты. Для борьбы с этой проблемой используется пакетная нормализация, которая позволяет нормализовать выходы каждого слоя в процессе обучения. Это делает распределение данных более стабильным и уменьшает влияние сдвига распределения на последующие слои~\cite{burkholz2024batch}. Такая проблема получила название внутреннего сдвига переменных.

В исследованиях, приведенных в статье~\cite{normalisation_lecun}, говорится, что процесс обучения сходится быстрее, когда входы нейронной сети нормализованы, то есть их математическое ожидание приведено к нулю, а матрица ковариаций -- к единичной. Если применять нормализацию к входам каждого слоя, то удастся избежать проблемы внутреннего сдвига переменных.

Для выполнения нормализации требуется предварительно рассчитать математическое ожидание и дисперсию элементов батча, которые определяются выражениями~(\ref{formula:normE}) и~(\ref{formula:normVar}) соответственно.

\begin{equation}\label{formula:normE}
\mu = \frac{1}{N} \sum\limits_{i=1}^{N}x_{\rm{i}},
\end{equation}
где $\mu$ -- математическое ожидание элементов бача, $N$ -- размер бача, $x_{\rm{i}}$ -- i-ый элемент бача.

\begin{equation}\label{formula:normVar}
\sigma^2 = \frac{1}{N} \sum\limits_{i=1}^{N}(x_{\rm{i}} - \mu)^2,
\end{equation}
где $\sigma$ -- дисперсия элементов бача, $N$ -- размер бача, $x_{\rm{i}}$ -- i-ый элемент бача, $\mu$ -- значение математического ожидания, посчитанное по формуле~(\ref{formula:normE}).

Тогда нормализацию входов можно проводить, используя выражение~(\ref{formula:norm})
\begin{equation}\label{formula:norm}
\hat{x_{\rm{i}}} = \frac{x_{\rm{i}} - \mu}{\sqrt{\sigma^2 + \epsilon}},
\end{equation}
где $\hat{x_{\rm{i}}}$ -- нормализованное значение i-го входа, $x_{\rm{i}}$ -- ненормализованное значение i-го входа, $\mu$ и $\sigma$ -- математическое ожидание и дисперсия, посчитанные по формулам~(\ref{formula:normE}) и~(\ref{formula:normVar}) соответственно, $\epsilon$ -- некоторая константа, которая нужна для предотвращения деления на ноль.

Такая нормализация имеет существенный недостаток: в случае, если в качестве функции активации слоя используется сигмоидальная функция, например логистическая, то после нормализации нелинейность, которую давала эта функция активации, пропадет, так как большинство значений будут попадать в область, где эта функция ведет себя линейно, и функция активации фактически станет линейной~\cite{normalisation}.

Для того, чтобы компенсировать этот недостаток, слой нормализации должен быть способен в некоторых случаях практически никак не менять входные значения. Достигается это при помощи введения двух новый коэффициентов: коэффициент масштарбирования и сдвига нормализации. Итоговое выражение для слоя нормализации определяется зависимостью~(\ref{formula:normfin})
\begin{equation}\label{formula:normfin}
y_{\rm{i}} = \gamma_{\rm{i}}\hat{x_{\rm{i}}} + \beta_{\rm{i}},
\end{equation}
где $y_{\rm{i}}$ -- i-ый выход слоя нормализации, $\hat{x_{\rm{i}}}$ -- величина, полученная из выражения~(\ref{formula:norm}), $\gamma_{\rm{i}}$ и $\beta_{\rm{i}}$ -- коэффициенты масштабирования и сдвига, которые настраиваются во время обучения модели.

Значения математического ожидания и дисперсии во время обучения от батча к батчу будут изменяться, но на этапе тестирования модели все изменяемые параметры должны быть зафиксированы. Для того, чтобы определить значения математического ожидания и дисперсии на этапе тестирования, эти величины накапливаются во время обучения с использованием экспоненциального скользящего среднего, которое определяется зависимостью~(\ref{formula:ema}) \begin{equation}\label{formula:ema}
E\!M\!A_{\rm{t}} = \alpha * x_{\rm{t}} + (1 - \alpha) * E\!M\!A_{\rm{t-1}},
\end{equation}
где $E\!M\!A_{\rm{t}}$ -- значение экспоненциального скользящего среднего в точке t, $E\!M\!A_{\rm{t-1}}$ -- значение экспоненциального скользящего среднего в точке t минус 1, причем значение экспоненциального скользящего среднего в нуле $E\!M\!A_{\rm{t}}$ равно $x_{\rm{0}}$, $x_{\rm{t}}$ -- значение исходной функции, в нашем случае это математическое ожидание или дисперсии, в момент времени t, $\alpha$ -- коэффициент характеризующий скорость уменьшения весов, принимает значение от 0 и до 1, чем меньше его значение тем больше влияние предыдущих значений на текущую величину среднего.

В случае, когда входной батч описывается кортежем (N, C, H, W), где N -- число элементов в батче, C -- число каналов в каждом элементе, H и W -- высота и ширина каждого изображения, нормализация считается по всем пикселям, всех изображений по каждому из каналов.

\section{Ансамблевые методы}
Ансамблевые методы классификации основаны на том, что несколько классификаторов обучаются на одном и том же наборе обучающих данных, а затем их прогнозы объединяются для классификации элементов тестового набора данных. Математическим обоснованием этой идеи служит теорема Кондорсье о жюри присяжных~\cite{ansambles}.

Классификатор называется слабым, если его ошибка на обучающей выборке менее 50 процентов, но больше нуля. Тогда, объединив предсказания нескольких таких классификаторов, можно достичь большей точности классификации на элементах тестовой выборки~\cite{ansambles}.

Выделяют 3 основных метода ансамблевой классификации~\cite{ansambles}:
\begin{itemize}
	\item бэггинг;
	\item бустинг;
	\item стекинг.
\end{itemize}

Идея бэггинга~\cite{ntayagabiri2025omic} состоит в том, что если размер обучающей выборки не велик, то можно создать много случайных выборок из исходной путем отбора некоторых элементов, и обучить слабые классификаторы на эти подвыборки. Таким образом, каждая модель имеет свой набор обучающих примеров и старается сделать предсказания на основе своего подмножества данных. Затем результаты всех моделей комбинируются для получения итоговых предсказаний.

Бустинг -- это процедура последовательного построения композиции алгоритмов машинного обучения, когда каждый следующий алгоритм стремится компенсировать недостатки композиции всех предыдущих алгоритмов~\cite{ansambles}. Таким образом, при бустинге каждая последующая модель обучается на ошибках предыдущей и старается их компенсировать, повышая точность классификации общей модели.

Идея стекинга~\cite{daza2024stacking} заключается в введении некоторого алгоритма классификации и его обучении. При стекинге, в отличие от бустинга и бэггинга, классификаторы должны быть разной природы~\cite{ansambles}. Обучение модели при стекинге можно свести к следующим трем шагам:
\begin{itemize}
	\item обучающая выборка разбивается на две непересекающихся подвыборки;
	\item первая подвыборка используется для обучения классификаторов;
	\item вторая для обучения алгоритма, который на вход принимает выходы со всех классификаторов.
\end{itemize}

Главным недостатком стекинга является деление обучающей выборки на две части.

\section{Формализованная постановка задачи}
Цель работы -- разработать метод замещения страниц в разделяемом кэш буфере Postgres с использованием нейронных сетей.

Для достижения поставленной цели требуется выполнить следующие задачи:
\begin{itemize}
	\item сравнить существующие методы замещения страниц;
	\item описать и спроектировать метод замещения страниц с использованием нейронных сетей;
	\item разработать программное обеспечение для предложенного метода;
	\item провести сравнение разработанного метода с существующими аналогами по коэффициентам совпадения и попадания.
\end{itemize}

На вход методу подается атрибуты страницы, к которой происходит обращение, и атрибуты всех страниц, которые уже находятся в буфере.
Результатом работы метода является индекс страницы для замещения в буфере.

На входные данные накладываются следующие ограничения:
\begin{itemize}
	\item размер буфера совпадает с тем, на котором обучалась модель;
	\item число страниц в буфере не больше 256;
	\item шаблон обращений к страницам совпадает с тем, на котором обучалась модель.
\end{itemize}

На рисунке~\ref{img:idef0A0} приведена IDEF-0 диаграмма уровня А0 метода замещения страниц в разделяемом кэш буфере Postgres с использованием нейронных сетей.

\includeimage
{idef0A0} % Имя файла без расширения (файл должен быть расположен в директории inc/img/)
{f} % Обтекание (без обтекания)
{H} % Положение рисунка (см. figure из пакета float)
{0.85\textwidth} % Ширина рисунка
{IDEF-0 диаграмма метода замещения страниц} % Подпись рисунка

\section{Вывод}
Управление памятью в операционных системах и СУБД, таких как PostgreSQL, основано на схожих принципах минимизации задержек при работе с диском.
В операционных системах ключевую роль играет виртуальная память, использующая страничную организацию и механизмы трансляции адресов, что позволяет эффективно распределять физическую память между процессами и избегать её переполнения за счёт выгрузки редко используемых страниц на диск. 

В PostgreSQL управление памятью адаптировано под специфику работы с базами данных. 
Разделяемый буферный кэш служит для хранения часто используемых страниц данных в оперативной памяти, что сокращает количество обращений к диску.
Однако это порождает проблему двойного кэширования, так как ОС также использует свой дисковый кэш.
PostgreSQL частично решает её, минимизируя взаимодействие с кэшем ОС: пока страница находится в буфере СУБД, обращения к ней идут напрямую.

Алгоритмы замещения страниц предлагают различные стратегии баланса между производительностью и ресурсозатратностью.
Теоретически оптимальный алгоритм демонстрирует максимальную эффективность, удаляя страницу с самым отдалённым обращением, но его практическая реализация невозможна из-за отсутствия данных о будущих запросах. 
Более простые методы, такие как NRU и FIFO с модификациями («второй шанс», «часы»), используют биты обращения и циклические списки для минимизации накладных расходов, однако их эффективность ограничена в динамичных сценариях.

Алгоритмы LRU с механизмом старения и WSClock учитывают не только количество обращений, но и время последнего обращения.

Эти методы демонстрируют удовлетворительную производительность в общих сценариях, но их эффективность снижается в условиях динамичных или нестандартных шаблонов доступа к данным.
Оптимальный алгоритм является хорошей метрикой для оценки алгоритмов замещения страниц -- чем больше различие результатов разработанного метода и оптимального, тем больше возможностей для улучшения разработанного алгоритма.
Таким образом, при разработке метода необходимо стараться приблизить его к результатам, которые выдает оптимальный алгоритм.

Нейронные сети предлагают перспективное решение для адаптивного управления кэшем.
Их ключевое преимущество -- способность обучаться на истории обращений к страницам, выявляя скрытые закономерности и прогнозируя востребованность данных. 
Это позволяет приблизить стратегию замещения к оптимальному алгоритму. 

Для запоминания последовательности обращений к страницам нужно использовать рекуррентные нейронные сети, так как они сохраняют информацию о предыдущих состояниях, что позволяет выявлять скрытые временные зависимости и прогнозировать востребованность страниц на основе контекста.

Для решения проблемы переобучения нейронных сетей нужно использовать: регуляризацию, которая вводит дополнительные ограничения на большие веса модели, нормализацию, которая приводит значения входных признаков к одному диапазону, а также метод раннего останова, который отслеживает момент, когда модель начинает переобучаться, и прекращает обучение в этот момент.
