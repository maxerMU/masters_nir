{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import seaborn as sns\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from dataclasses import dataclass, fields, asdict\n",
    "from model.model import PageAccModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Page:\n",
    "    buffer: int\n",
    "    # is_local_temp: int\n",
    "    fork_num: int\n",
    "    block_num: int\n",
    "    # mode: int\n",
    "    relam: int\n",
    "    relfilenode: int\n",
    "    relhasindex: int\n",
    "    # relpersistence: int\n",
    "    relkind: int\n",
    "    relnatts: int\n",
    "    relfrozenxid: int\n",
    "    relminmxid: int\n",
    "    hit: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data/acc_logfile2\", \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "pattern = r\"buffer={(\\d+)} is_local_temp={(\\w+)} fork_num={(\\w+)} block_num={(\\d+)} mode={(\\w+)} strategy={} relam={(\\d+)} relfilenode={(\\d+)} relhasindex={(\\w+)} relpersistence={(\\w+)} relkind={(\\w+)} relnatts={(\\d+)} relfrozenxid={(\\d+)} relminmxid={(\\d+)} hit={(\\w+)}\"\n",
    "matches = re.findall(pattern, data)\n",
    "\n",
    "pages = []\n",
    "\n",
    "for match in matches:\n",
    "    buffer = int(match[0])\n",
    "    is_local_temp = 1 if match[1] == \"true\" else 0\n",
    "    fork_num = [\"MAIN_FORKNUM\", \"FSM_FORKNUM\", \"VISIBILITYMAP_FORKNUM\", \"INIT_FORKNUM\"].index(match[2])\n",
    "    block_num = int(match[3])\n",
    "    mode = [\"RBM_NORMAL\", \"RBM_ZERO_AND_LOCK\", \"RBM_ZERO_AND_CLEANUP_LOCK\", \"RBM_ZERO_ON_ERROR\", \"RBM_NORMAL_NO_LOG\"].index(match[4])\n",
    "    relam = int(match[5])\n",
    "    relfilenode = int(match[6])\n",
    "    relhasindex = 1 if match[7] == \"true\" else 0\n",
    "    relpersistence = [\"p\", \"u\", \"t\"].index(match[8])\n",
    "    relkind = [\"r\", \"i\", \"S\", \"t\", \"v\", \"m\", \"c\", \"f\", \"p\", \"I\"].index(match[9])\n",
    "    relnatts = int(match[10])\n",
    "    relfrozenxid = int(match[11])\n",
    "    relminmxid = int(match[12])\n",
    "    hit = 1 if match[13] == \"true\" else 0\n",
    "\n",
    "    page = Page(\n",
    "        buffer,\n",
    "        # is_local_temp, \n",
    "        fork_num,\n",
    "        block_num,\n",
    "        #mode,\n",
    "        relam,\n",
    "        relfilenode,\n",
    "        relhasindex,\n",
    "        # relpersistence,\n",
    "        relkind,\n",
    "        relnatts,\n",
    "        relfrozenxid,\n",
    "        relminmxid,\n",
    "        hit,\n",
    "    )\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_data/acc_logfile2_pages\", \"w\") as f:\n",
    "    for page in pages:\n",
    "        f.write(f\"{page.buffer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024067\n"
     ]
    }
   ],
   "source": [
    "print(len(pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_results = []\n",
    "with open(\"train_data/acc_logfile2_victims\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        victims_count = int(line)\n",
    "        victims_rates = []\n",
    "        for _ in range(victims_count):\n",
    "            victim_rate = f.readline().strip().split()\n",
    "            victims_rates.append([int(victim_rate[0]), int(victim_rate[1])])\n",
    "\n",
    "        optimal_results.append(victims_rates)\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024067"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(optimal_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = len(pages)\n",
    "BATCH_SIZE = 2048\n",
    "BUFFER_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024067"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6318912727389907"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([page.hit for page in pages[:TRAIN_SIZE]]) / TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6844718167854251"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find_optimal_hit_rate([page.buffer for page in pages[:TRAIN_SIZE]], BUFFER_SIZE)\n",
    "sum([1 if len(victims) == 0 else 0 for victims in optimal_results[:TRAIN_SIZE]]) / TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot([victims[0][0] for victims in optimal_results[:TRAIN_SIZE] if len(victims) != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='None'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.histplot([page.is_local_temp for page in pages], discrete=True)\n",
    "# sns.histplot([page.mode for page in pages], discrete=True)\n",
    "\n",
    "# sns.histplot([page.relam for page in pages], discrete=True)\n",
    "data = pd.Series([page.relminmxid for page in pages])\n",
    "value_counts = data.value_counts()\n",
    "sns.barplot(x=value_counts.index, y=value_counts.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_optimal_res(pages, buffer, current_index):\n",
    "    res = [0] * (len(buffer) + 1)\n",
    "    if (current_index >= len(pages)):\n",
    "        print(f\"ERROR: current_index=={current_index} pages.size() == {len(pages)}\")\n",
    "\n",
    "    already_in_buf = any(buf.buffer == pages[current_index].buffer for buf in buffer)\n",
    "    if already_in_buf:\n",
    "        res[-1] = 1\n",
    "        return res, -1\n",
    "    \n",
    "    empty_pages = [index for index, value in enumerate(buffer) if value.buffer == -1]\n",
    "    if len(empty_pages) > 0:\n",
    "        for i in empty_pages:\n",
    "            res[i] = 1 / len(empty_pages)\n",
    "        \n",
    "        return res, empty_pages[0]\n",
    "    \n",
    "    #victim = find_optimal_victim(pages, [page.buffer for page in buffer], current_index)\n",
    "    victims_rates = optimal_results[current_index]\n",
    "    victim_rates_sum = sum([victim[1] for victim in victims_rates])\n",
    "    for victim, rate in victims_rates:\n",
    "        res[victim] = rate / victim_rates_sum\n",
    "\n",
    "    return res, victims_rates[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(pages, buffer, batch_start, batch_end):\n",
    "    pages_acc = torch.Tensor([list(asdict(page).values()) for page in pages[batch_start:batch_end]])\n",
    "\n",
    "    buffers = []\n",
    "    optimal_predictions = []\n",
    "\n",
    "    for i in range(batch_start, batch_end):\n",
    "        if i == TRAIN_SIZE:\n",
    "            print(f\"STRANGE: i=={i} bathc_end=={batch_end}\")\n",
    "\n",
    "        buffers.append([value for obj in buffer for value in asdict(obj).values()])\n",
    "\n",
    "        res, victim = get_model_optimal_res(pages, buffer, i)\n",
    "        optimal_predictions.append(res)\n",
    "\n",
    "        if victim >= 0:\n",
    "            buffer[victim] = pages[i]\n",
    "            buffer[victim].hit = True\n",
    "            pages_acc[i - batch_start][-1] = False\n",
    "        else:\n",
    "            pages_acc[i - batch_start][-1] = True\n",
    "    \n",
    "    return pages_acc, torch.Tensor(buffers), torch.Tensor(optimal_predictions), buffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PageAccModel(len(fields(Page)), 32, BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 501/501 [07:06<00:00,  1.18it/s, loss=3.0875650296211243]\n",
      "100%|██████████| 501/501 [07:09<00:00,  1.17it/s, loss=2.862814152240753] \n",
      "100%|██████████| 501/501 [07:03<00:00,  1.18it/s, loss=2.8628084564208987]\n",
      " 82%|████████▏ | 409/501 [05:21<01:12,  1.27it/s, loss=2.863039978558976] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_end \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m TRAIN_SIZE:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m pages_acc, buffers, optimal_predictions, buffer \u001b[38;5;241m=\u001b[39m \u001b[43mget_train_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     21\u001b[0m out, h, c \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(pages_acc, buffers, h, c)\n",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m, in \u001b[0;36mget_train_data\u001b[0;34m(pages, buffer, batch_start, batch_end)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m TRAIN_SIZE:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTRANGE: i==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bathc_end==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m buffers\u001b[38;5;241m.\u001b[39mappend(\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m res, victim \u001b[38;5;241m=\u001b[39m get_model_optimal_res(pages, buffer, i)\n\u001b[1;32m     14\u001b[0m optimal_predictions\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "Cell \u001b[0;32mIn[44], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m TRAIN_SIZE:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTRANGE: i==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bathc_end==\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m buffers\u001b[38;5;241m.\u001b[39mappend([value \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m buffer \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[43masdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues()])\n\u001b[1;32m     13\u001b[0m res, victim \u001b[38;5;241m=\u001b[39m get_model_optimal_res(pages, buffer, i)\n\u001b[1;32m     14\u001b[0m optimal_predictions\u001b[38;5;241m.\u001b[39mappend(res)\n",
      "File \u001b[0;32m/usr/lib/python3.11/dataclasses.py:1275\u001b[0m, in \u001b[0;36masdict\u001b[0;34m(obj, dict_factory)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_dataclass_instance(obj):\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masdict() should be called on dataclass instances\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_asdict_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_factory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/dataclasses.py:1284\u001b[0m, in \u001b[0;36m_asdict_inner\u001b[0;34m(obj, dict_factory)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         value \u001b[38;5;241m=\u001b[39m _asdict_inner(\u001b[38;5;28mgetattr\u001b[39m(obj, f\u001b[38;5;241m.\u001b[39mname), dict_factory)\n\u001b[1;32m   1283\u001b[0m         result\u001b[38;5;241m.\u001b[39mappend((f\u001b[38;5;241m.\u001b[39mname, value))\n\u001b[0;32m-> 1284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_factory(result)\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# obj is a namedtuple.  Recurse into it, but the returned\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;66;03m# object is another namedtuple of the same type.  This is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;66;03m#   namedtuples, we could no longer call asdict() on a data\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m#   structure where a namedtuple was used as a dict key.\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m[_asdict_inner(v, dict_factory) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m obj])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "h, c = None, None\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    buffer = [Page(-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0)] * BUFFER_SIZE\n",
    "\n",
    "    loss_sum = 0\n",
    "    pbar = tqdm(range(0, TRAIN_SIZE, BATCH_SIZE))\n",
    "    for i in pbar:\n",
    "        batch_start = i\n",
    "        # batch_end = i + BATCH_SIZE if i + BATCH_SIZE < TRAIN_SIZE else TRAIN_SIZE\n",
    "        batch_end = i + BATCH_SIZE\n",
    "        if batch_end >= TRAIN_SIZE:\n",
    "            continue\n",
    "        pages_acc, buffers, optimal_predictions, buffer = get_train_data(pages, buffer, batch_start, batch_end)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        out, h, c = model.forward(pages_acc, buffers, h, c)\n",
    "        # print(out)\n",
    "    \n",
    "        loss_value = loss(out, optimal_predictions)\n",
    "    \n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        h = h.detach()\n",
    "        c = c.detach()\n",
    "\n",
    "        loss_sum += loss_value.item()\n",
    "        loss_avg = loss_sum / (batch_end // BATCH_SIZE)\n",
    "\n",
    "        pbar.set_postfix_str(f\"loss={loss_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TEST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PageAccModel(\n",
       "  (_page_acc_enc): Sequential(\n",
       "    (0): Linear(in_features=14, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (_lstm): LSTM(32, 32, batch_first=True)\n",
       "  (_buf_page_enc): Sequential(\n",
       "    (0): Linear(in_features=448, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (_page_evict): Sequential(\n",
       "    (0): Linear(in_features=1056, out_features=33, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:00<00:00, 366.24it/s, loss=3.0541157983753777]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "tensor([[1.0576e-07, 6.9543e-07, 2.7547e-08, 1.1713e-07, 4.9775e-08, 1.2914e-07,\n",
      "         1.2513e-07, 1.1280e-07, 2.3495e-07, 7.7850e-07, 1.4121e-07, 1.3179e-07,\n",
      "         9.5770e-08, 1.5972e-07, 2.8003e-07, 1.4653e-07, 1.3451e-07, 1.9367e-05,\n",
      "         1.2549e-07, 1.1390e-07, 5.3456e-08, 1.7795e-07, 2.1507e-07, 1.1796e-06,\n",
      "         2.2322e-07, 7.7013e-08, 7.4431e-08, 1.5174e-07, 2.0315e-07, 2.0360e-07,\n",
      "         8.9978e-09, 8.8734e-08, 9.9997e-01]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0312,\n",
      "         0.0312, 0.0312, 0.0312, 0.0312, 0.0312, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[8.7579e-10, 5.3650e-09, 1.6056e-10, 7.9616e-10, 4.0915e-10, 5.5256e-10,\n",
      "         6.2544e-10, 6.2721e-10, 1.0848e-09, 5.1453e-09, 6.1149e-10, 4.2770e-10,\n",
      "         3.8709e-10, 4.8108e-10, 7.9430e-10, 7.1809e-10, 6.8462e-10, 6.1297e-08,\n",
      "         5.4047e-10, 7.6914e-10, 3.4588e-10, 1.0776e-09, 9.5763e-10, 1.5823e-08,\n",
      "         1.1598e-09, 2.7381e-10, 3.5281e-10, 6.2929e-10, 1.2527e-09, 6.3844e-10,\n",
      "         5.1844e-11, 2.4181e-10, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323,\n",
      "         0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323,\n",
      "         0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0323,\n",
      "         0.0323, 0.0323, 0.0323, 0.0323, 0.0323, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[7.2008e-11, 2.7945e-10, 8.4740e-12, 3.5811e-11, 1.9166e-11, 2.9737e-11,\n",
      "         4.4243e-11, 3.5198e-11, 5.4257e-11, 1.3681e-10, 2.6218e-11, 1.9366e-11,\n",
      "         2.0389e-11, 1.5431e-11, 3.5779e-11, 3.4235e-11, 3.5552e-11, 1.2175e-09,\n",
      "         2.2535e-11, 3.3281e-11, 1.4267e-11, 3.4204e-11, 3.8474e-11, 8.9511e-10,\n",
      "         6.5919e-11, 9.6452e-12, 1.3768e-11, 2.2610e-11, 5.9233e-11, 1.7751e-11,\n",
      "         2.9656e-12, 7.0588e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[7.1039e-11, 2.7672e-10, 8.3695e-12, 3.5506e-11, 1.8874e-11, 2.9644e-11,\n",
      "         4.3834e-11, 3.4700e-11, 5.3553e-11, 1.3361e-10, 2.6077e-11, 1.9140e-11,\n",
      "         2.0329e-11, 1.5121e-11, 3.5056e-11, 3.3832e-11, 3.4966e-11, 1.1925e-09,\n",
      "         2.2165e-11, 3.2440e-11, 1.3977e-11, 3.3437e-11, 3.7659e-11, 8.7667e-10,\n",
      "         6.4322e-11, 9.4508e-12, 1.3572e-11, 2.2274e-11, 5.8214e-11, 1.7384e-11,\n",
      "         2.9158e-12, 6.9450e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[7.0631e-11, 2.7510e-10, 8.3393e-12, 3.5369e-11, 1.8771e-11, 2.9546e-11,\n",
      "         4.3590e-11, 3.4543e-11, 5.3109e-11, 1.3256e-10, 2.5955e-11, 1.9035e-11,\n",
      "         2.0238e-11, 1.4995e-11, 3.4792e-11, 3.3622e-11, 3.4733e-11, 1.1826e-09,\n",
      "         2.2054e-11, 3.2182e-11, 1.3836e-11, 3.3151e-11, 3.7440e-11, 8.7018e-10,\n",
      "         6.3651e-11, 9.3793e-12, 1.3494e-11, 2.2085e-11, 5.7795e-11, 1.7270e-11,\n",
      "         2.8913e-12, 6.8847e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[6.8604e-11, 2.7447e-10, 8.1137e-12, 3.5123e-11, 1.8119e-11, 2.9472e-11,\n",
      "         4.3076e-11, 3.3529e-11, 5.2127e-11, 1.2743e-10, 2.6130e-11, 1.8740e-11,\n",
      "         2.0235e-11, 1.4756e-11, 3.3485e-11, 3.2907e-11, 3.3622e-11, 1.1380e-09,\n",
      "         2.1186e-11, 3.0800e-11, 1.3541e-11, 3.2137e-11, 3.6578e-11, 8.3613e-10,\n",
      "         6.1336e-11, 9.0969e-12, 1.3212e-11, 2.1736e-11, 5.6147e-11, 1.6713e-11,\n",
      "         2.8776e-12, 6.8036e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333,\n",
      "         0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333,\n",
      "         0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0333,\n",
      "         0.0333, 0.0333, 0.0333, 0.0333, 0.0333, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[5.2359e-11, 2.1821e-10, 6.9241e-12, 1.6387e-11, 1.2149e-11, 1.7067e-11,\n",
      "         2.0313e-11, 3.1372e-11, 6.0757e-11, 1.7452e-10, 1.3533e-11, 1.0948e-11,\n",
      "         7.2226e-11, 1.7289e-11, 2.6567e-11, 4.0163e-11, 4.1044e-11, 5.2748e-10,\n",
      "         1.2349e-11, 3.7862e-11, 1.7437e-11, 4.6844e-11, 3.9566e-11, 4.3378e-09,\n",
      "         7.6747e-11, 2.0122e-11, 4.1718e-11, 1.0290e-10, 1.8699e-10, 4.5964e-11,\n",
      "         4.7834e-11, 2.0203e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
      "         0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
      "         0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0345,\n",
      "         0.0345, 0.0345, 0.0345, 0.0345, 0.0345, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[4.7895e-12, 1.4113e-10, 1.1190e-12, 2.8312e-12, 3.5189e-12, 1.9104e-12,\n",
      "         1.5328e-12, 6.0564e-12, 6.7525e-12, 1.2335e-10, 6.3872e-12, 2.5742e-12,\n",
      "         2.8486e-11, 1.3192e-11, 3.2525e-12, 9.4626e-12, 8.8353e-12, 9.5764e-11,\n",
      "         4.1148e-12, 1.3175e-11, 3.7810e-12, 1.7647e-11, 1.7513e-11, 5.8499e-09,\n",
      "         1.7685e-11, 4.7090e-12, 1.2332e-11, 6.4535e-11, 2.0079e-10, 8.7661e-12,\n",
      "         8.0833e-11, 1.9498e-11, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357,\n",
      "         0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357,\n",
      "         0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0357,\n",
      "         0.0357, 0.0357, 0.0357, 0.0357, 0.0357, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[3.0831e-13, 1.8056e-11, 2.2193e-13, 2.8081e-13, 4.1424e-13, 1.1335e-13,\n",
      "         1.1914e-13, 3.6424e-13, 7.0805e-13, 1.9949e-11, 1.1765e-12, 1.5544e-13,\n",
      "         3.7278e-12, 3.7066e-12, 3.2609e-13, 2.3880e-12, 1.7384e-12, 8.7668e-12,\n",
      "         1.1566e-12, 1.4463e-12, 3.5986e-13, 2.3896e-12, 1.6003e-12, 3.6516e-09,\n",
      "         2.1873e-12, 4.9703e-13, 3.6638e-12, 3.0286e-11, 7.8505e-11, 2.2699e-12,\n",
      "         3.7174e-11, 5.2560e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "         0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[6.3388e-14, 5.2714e-12, 3.4390e-14, 5.2612e-14, 7.9454e-14, 4.4736e-14,\n",
      "         9.7061e-15, 4.5625e-14, 2.3122e-13, 1.0894e-11, 1.2710e-13, 2.1347e-14,\n",
      "         1.3451e-12, 1.1531e-12, 1.1360e-13, 5.2669e-13, 1.1259e-12, 1.1796e-12,\n",
      "         3.6703e-13, 2.4299e-13, 6.7795e-14, 2.4609e-13, 1.2980e-12, 3.9589e-09,\n",
      "         7.3651e-13, 3.1767e-13, 1.9977e-12, 2.1539e-11, 2.1472e-11, 5.3330e-13,\n",
      "         4.2881e-11, 3.6468e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0385, 0.0385, 0.0385,\n",
      "         0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385,\n",
      "         0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0385,\n",
      "         0.0385, 0.0385, 0.0385, 0.0385, 0.0385, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5668e-14, 3.4941e-12, 7.8073e-15, 1.7077e-14, 3.2502e-14, 2.1156e-14,\n",
      "         1.4611e-15, 8.7849e-15, 3.8901e-14, 5.0004e-12, 1.5369e-14, 4.1888e-15,\n",
      "         8.7927e-13, 2.5536e-13, 2.2299e-14, 2.6356e-13, 5.4456e-13, 3.4478e-13,\n",
      "         1.0080e-13, 1.4331e-13, 1.4698e-14, 9.5437e-14, 7.6017e-13, 3.7075e-09,\n",
      "         3.1549e-13, 1.7635e-13, 8.8831e-13, 1.2093e-11, 6.3384e-12, 1.8866e-13,\n",
      "         5.9125e-11, 2.0895e-12, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0400,\n",
      "         0.0400, 0.0400, 0.0400, 0.0400, 0.0400, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[3.2876e-15, 1.0327e-12, 1.2904e-15, 3.5025e-15, 5.7076e-15, 1.8611e-15,\n",
      "         1.4864e-16, 1.9820e-15, 4.7074e-15, 1.5672e-12, 2.3362e-15, 6.3950e-16,\n",
      "         1.3160e-13, 5.0174e-14, 3.9447e-15, 4.8185e-14, 1.1670e-13, 3.2933e-14,\n",
      "         2.5018e-14, 3.9250e-14, 2.7717e-15, 2.3093e-14, 1.9399e-13, 1.8013e-09,\n",
      "         3.5211e-14, 4.4684e-14, 1.4369e-13, 2.7603e-12, 1.5258e-12, 3.9513e-14,\n",
      "         2.4830e-11, 5.5430e-13, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0417,\n",
      "         0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417,\n",
      "         0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0417,\n",
      "         0.0417, 0.0417, 0.0417, 0.0417, 0.0417, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[2.3858e-16, 1.6267e-13, 1.6322e-16, 5.7063e-16, 4.0357e-16, 2.6284e-16,\n",
      "         6.9353e-18, 1.6328e-16, 6.4742e-16, 5.4504e-13, 1.4662e-16, 2.9843e-17,\n",
      "         2.2660e-14, 3.0483e-15, 3.4279e-16, 4.3945e-15, 8.0586e-15, 9.8638e-16,\n",
      "         4.6711e-15, 2.4554e-15, 2.1102e-16, 3.5034e-15, 1.9118e-14, 3.1488e-10,\n",
      "         3.3929e-15, 4.3122e-15, 6.6173e-14, 3.2236e-13, 5.4939e-13, 1.1707e-14,\n",
      "         8.7624e-12, 6.3860e-14, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435,\n",
      "         0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0435,\n",
      "         0.0435, 0.0435, 0.0435, 0.0435, 0.0435, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.7267e-17, 9.4464e-15, 1.4217e-17, 2.2084e-17, 5.8135e-17, 1.2110e-17,\n",
      "         6.3894e-19, 8.6923e-18, 7.5987e-17, 5.3093e-14, 7.6548e-18, 1.6261e-18,\n",
      "         1.9774e-15, 3.1055e-16, 2.1838e-17, 1.8873e-16, 4.8939e-16, 5.7036e-17,\n",
      "         4.5888e-16, 1.8671e-16, 1.1512e-17, 3.8280e-16, 8.2231e-16, 9.0329e-11,\n",
      "         2.6149e-16, 5.5472e-16, 8.9368e-15, 3.1241e-14, 7.0068e-14, 1.2909e-15,\n",
      "         2.6414e-12, 3.3632e-15, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455,\n",
      "         0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0455,\n",
      "         0.0455, 0.0455, 0.0455, 0.0455, 0.0455, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[3.2632e-19, 8.4315e-16, 4.4126e-19, 1.5831e-18, 4.2499e-18, 3.1905e-19,\n",
      "         1.6036e-20, 2.5439e-19, 1.8312e-18, 4.5346e-15, 2.4044e-19, 3.9286e-20,\n",
      "         4.3512e-17, 6.3040e-18, 5.3709e-19, 3.7570e-18, 2.0342e-17, 1.4751e-18,\n",
      "         2.0247e-17, 1.1195e-17, 4.7446e-19, 1.4593e-17, 6.4680e-17, 7.9826e-12,\n",
      "         9.2641e-18, 2.2710e-17, 7.2265e-16, 1.6377e-15, 4.0820e-15, 4.8517e-17,\n",
      "         2.0032e-13, 5.9919e-17, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476,\n",
      "         0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0476,\n",
      "         0.0476, 0.0476, 0.0476, 0.0476, 0.0476, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.0828e-20, 2.7780e-17, 1.6810e-20, 8.5862e-20, 1.7246e-19, 1.5301e-20,\n",
      "         6.0933e-22, 2.2799e-20, 7.0819e-20, 3.4233e-16, 5.5661e-21, 1.2584e-21,\n",
      "         2.0686e-18, 6.9286e-20, 1.2144e-20, 1.2227e-19, 1.5203e-18, 6.5025e-20,\n",
      "         5.2552e-19, 2.8954e-19, 1.8400e-20, 5.1875e-19, 2.9503e-18, 9.9670e-13,\n",
      "         2.9456e-19, 1.4182e-18, 1.5787e-17, 3.2469e-17, 1.1570e-16, 1.1018e-18,\n",
      "         1.1295e-14, 1.2610e-18, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,\n",
      "         0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[2.3859e-22, 7.0739e-19, 6.0192e-22, 1.3858e-21, 3.0697e-21, 4.2966e-22,\n",
      "         8.1865e-24, 4.4822e-22, 1.5292e-21, 2.0315e-17, 8.4178e-23, 1.4759e-23,\n",
      "         2.8331e-20, 1.1517e-21, 1.7074e-22, 2.6417e-21, 1.6472e-20, 7.7550e-22,\n",
      "         1.2665e-20, 4.9687e-21, 4.2483e-22, 1.5535e-20, 7.4976e-20, 1.0156e-13,\n",
      "         5.0900e-21, 3.1178e-20, 5.4581e-19, 5.8737e-19, 2.0757e-18, 1.6032e-20,\n",
      "         7.1733e-16, 4.9261e-20, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526,\n",
      "         0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526,\n",
      "         0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[4.0391e-24, 5.4656e-20, 1.1658e-23, 2.3787e-23, 8.9080e-23, 5.0018e-24,\n",
      "         8.6436e-26, 1.3995e-23, 6.5600e-23, 1.2949e-18, 1.7884e-24, 2.4487e-25,\n",
      "         3.7303e-22, 2.1954e-23, 4.9668e-24, 5.7145e-23, 1.9556e-22, 1.0876e-23,\n",
      "         1.2167e-22, 9.1615e-23, 7.5694e-24, 4.2755e-22, 1.5609e-21, 8.6157e-15,\n",
      "         8.0587e-23, 3.5887e-22, 8.2084e-21, 2.2926e-20, 3.1220e-20, 2.7473e-22,\n",
      "         5.5558e-17, 9.7510e-22, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0556, 0.0556, 0.0556, 0.0556,\n",
      "         0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556,\n",
      "         0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[3.5301e-26, 5.4811e-22, 1.2253e-25, 2.6021e-25, 7.5322e-25, 2.7287e-26,\n",
      "         5.5515e-28, 1.0663e-25, 9.7910e-25, 2.4591e-20, 8.6368e-27, 1.8284e-27,\n",
      "         2.2161e-24, 1.9138e-25, 2.4074e-26, 5.9516e-25, 1.0417e-24, 7.0550e-26,\n",
      "         6.1262e-25, 8.9228e-25, 7.0496e-26, 5.5707e-24, 1.4094e-23, 1.5502e-16,\n",
      "         8.1520e-25, 3.4264e-24, 9.5650e-23, 1.3859e-22, 4.6949e-22, 3.1256e-24,\n",
      "         1.9051e-18, 6.3068e-24, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588, 0.0588, 0.0588,\n",
      "         0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588,\n",
      "         0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5649e-27, 4.3230e-23, 5.7964e-27, 2.5784e-26, 3.4051e-26, 1.6578e-27,\n",
      "         1.5222e-29, 4.4946e-27, 5.9478e-26, 1.9770e-21, 6.3928e-28, 7.2427e-29,\n",
      "         8.8257e-26, 8.2240e-27, 5.6991e-28, 4.7031e-26, 1.0839e-25, 2.1182e-27,\n",
      "         3.5941e-26, 2.0940e-26, 4.1165e-27, 2.4282e-25, 6.4013e-25, 1.5112e-17,\n",
      "         3.9088e-26, 1.9921e-25, 9.9443e-24, 6.5279e-24, 2.3757e-23, 5.0518e-25,\n",
      "         1.1000e-19, 3.5112e-25, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,\n",
      "         0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[4.7452e-29, 1.0509e-24, 5.1588e-29, 3.0367e-28, 3.9534e-28, 1.3974e-29,\n",
      "         1.0735e-31, 3.0521e-29, 2.2870e-28, 3.7739e-23, 5.6602e-30, 5.8913e-31,\n",
      "         1.6197e-27, 1.3629e-28, 8.1553e-30, 6.0776e-28, 1.1873e-27, 7.0842e-30,\n",
      "         7.4048e-28, 1.8034e-28, 3.6500e-29, 1.6914e-27, 6.0570e-27, 1.1331e-18,\n",
      "         3.8424e-28, 1.8505e-27, 3.8640e-25, 7.6286e-26, 7.0934e-25, 9.2762e-27,\n",
      "         1.0441e-20, 4.9248e-27, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0667,\n",
      "         0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667,\n",
      "         0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[7.5322e-31, 4.5290e-26, 1.0630e-30, 4.3582e-30, 7.9008e-30, 1.7315e-31,\n",
      "         3.9352e-33, 1.4051e-30, 6.6832e-30, 2.0533e-24, 8.9918e-32, 7.0120e-33,\n",
      "         3.3018e-29, 2.8009e-30, 1.8600e-31, 1.0641e-29, 2.1890e-29, 9.5108e-32,\n",
      "         2.9881e-29, 4.1802e-30, 8.0857e-31, 7.4018e-29, 1.4562e-28, 2.0430e-20,\n",
      "         3.8211e-30, 2.0121e-29, 9.0156e-27, 7.7400e-28, 2.1799e-26, 1.0106e-28,\n",
      "         3.1737e-22, 4.3919e-29, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,\n",
      "         0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[4.4864e-33, 3.3521e-28, 1.4184e-32, 3.3561e-32, 5.1961e-32, 1.2642e-33,\n",
      "         1.4941e-35, 9.0798e-33, 7.1407e-32, 2.4960e-26, 5.1094e-34, 4.7092e-35,\n",
      "         1.9153e-31, 2.4085e-32, 1.4376e-33, 8.1285e-32, 1.2047e-31, 4.3673e-34,\n",
      "         1.1530e-31, 4.7379e-32, 1.0816e-32, 3.4876e-31, 1.2354e-30, 7.2157e-22,\n",
      "         3.4681e-32, 1.3448e-31, 8.4096e-29, 5.0710e-30, 5.0595e-28, 1.4845e-30,\n",
      "         9.9929e-24, 5.7211e-31, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769,\n",
      "         0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[2.7102e-35, 4.4103e-30, 5.0152e-35, 1.3045e-34, 9.5755e-35, 4.6002e-36,\n",
      "         2.3260e-38, 1.8935e-35, 2.1435e-34, 8.3281e-29, 3.3256e-36, 1.3688e-37,\n",
      "         7.3159e-34, 1.0066e-34, 7.1424e-36, 3.8824e-34, 3.1538e-34, 7.7122e-37,\n",
      "         2.6544e-34, 2.5523e-34, 1.8959e-35, 2.3808e-33, 6.5014e-33, 6.8447e-24,\n",
      "         1.1850e-34, 3.7666e-34, 2.4364e-31, 1.3662e-32, 4.1718e-30, 9.6869e-33,\n",
      "         2.3036e-25, 2.0824e-33, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833,\n",
      "         0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.3844e-38, 3.0296e-33, 9.5393e-39, 4.6458e-38, 6.4644e-38, 1.6946e-39,\n",
      "         7.1340e-42, 9.1263e-39, 1.0897e-37, 2.2750e-31, 6.4294e-40, 3.2221e-41,\n",
      "         3.4728e-37, 4.2798e-38, 6.8530e-39, 1.3845e-37, 3.7226e-37, 1.5533e-40,\n",
      "         3.1303e-37, 5.2001e-38, 1.0240e-38, 1.7123e-36, 1.9489e-36, 4.6526e-26,\n",
      "         3.0922e-38, 1.1413e-37, 1.1213e-34, 1.4548e-35, 3.3619e-33, 4.7679e-36,\n",
      "         4.2207e-28, 8.6720e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909,\n",
      "         0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6257e-40, 1.0012e-34, 8.1394e-41, 5.4966e-40, 1.3471e-39, 3.2088e-41,\n",
      "         8.2677e-44, 6.8126e-41, 1.6079e-39, 5.7784e-33, 1.0356e-41, 3.1109e-43,\n",
      "         3.8039e-39, 9.6586e-40, 8.2731e-41, 4.7599e-39, 5.8186e-39, 1.3915e-42,\n",
      "         3.6610e-39, 1.3720e-39, 1.1313e-40, 1.3523e-38, 2.1587e-38, 1.9302e-27,\n",
      "         2.8543e-40, 1.1122e-39, 1.5281e-36, 2.2875e-37, 2.4479e-35, 9.6345e-38,\n",
      "         1.8838e-29, 9.3250e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6332e-40, 9.9558e-35, 8.1645e-41, 5.4737e-40, 1.3470e-39, 3.2226e-41,\n",
      "         8.2677e-44, 6.7803e-41, 1.6203e-39, 5.7826e-33, 1.0273e-41, 3.1249e-43,\n",
      "         3.8283e-39, 9.6318e-40, 8.3265e-41, 4.7619e-39, 5.8324e-39, 1.3971e-42,\n",
      "         3.6777e-39, 1.3792e-39, 1.1351e-40, 1.3447e-38, 2.1425e-38, 1.9472e-27,\n",
      "         2.8666e-40, 1.1096e-39, 1.5237e-36, 2.2822e-37, 2.4401e-35, 9.6780e-38,\n",
      "         1.8888e-29, 9.2896e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6399e-40, 9.9178e-35, 8.1805e-41, 5.4704e-40, 1.3421e-39, 3.2280e-41,\n",
      "         8.2677e-44, 6.7513e-41, 1.6328e-39, 5.7997e-33, 1.0206e-41, 3.1529e-43,\n",
      "         3.8472e-39, 9.6256e-40, 8.3704e-41, 4.7694e-39, 5.8506e-39, 1.4055e-42,\n",
      "         3.6883e-39, 1.3882e-39, 1.1406e-40, 1.3401e-38, 2.1394e-38, 1.9635e-27,\n",
      "         2.8792e-40, 1.1088e-39, 1.5223e-36, 2.2806e-37, 2.4319e-35, 9.7449e-38,\n",
      "         1.8992e-29, 9.2897e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6458e-40, 9.8970e-35, 8.1933e-41, 5.4765e-40, 1.3373e-39, 3.2301e-41,\n",
      "         8.2677e-44, 6.7353e-41, 1.6428e-39, 5.8192e-33, 1.0161e-41, 3.1669e-43,\n",
      "         3.8615e-39, 9.6267e-40, 8.4077e-41, 4.7784e-39, 5.8677e-39, 1.4125e-42,\n",
      "         3.6969e-39, 1.3963e-39, 1.1468e-40, 1.3379e-38, 2.1415e-38, 1.9769e-27,\n",
      "         2.8911e-40, 1.1089e-39, 1.5226e-36, 2.2798e-37, 2.4255e-35, 9.8108e-38,\n",
      "         1.9097e-29, 9.3025e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6514e-40, 9.8869e-35, 8.2042e-41, 5.4862e-40, 1.3339e-39, 3.2301e-41,\n",
      "         8.4078e-44, 6.7302e-41, 1.6513e-39, 5.8397e-33, 1.0127e-41, 3.1809e-43,\n",
      "         3.8725e-39, 9.6324e-40, 8.4410e-41, 4.7884e-39, 5.8850e-39, 1.4195e-42,\n",
      "         3.7045e-39, 1.4038e-39, 1.1528e-40, 1.3377e-38, 2.1458e-38, 1.9884e-27,\n",
      "         2.9033e-40, 1.1099e-39, 1.5242e-36, 2.2801e-37, 2.4217e-35, 9.8741e-38,\n",
      "         1.9188e-29, 9.3209e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6568e-40, 9.8841e-35, 8.2141e-41, 5.4974e-40, 1.3316e-39, 3.2290e-41,\n",
      "         8.4078e-44, 6.7321e-41, 1.6589e-39, 5.8606e-33, 1.0103e-41, 3.1950e-43,\n",
      "         3.8815e-39, 9.6414e-40, 8.4724e-41, 4.7992e-39, 5.9027e-39, 1.4251e-42,\n",
      "         3.7115e-39, 1.4106e-39, 1.1586e-40, 1.3388e-38, 2.1511e-38, 1.9983e-27,\n",
      "         2.9157e-40, 1.1114e-39, 1.5266e-36, 2.2813e-37, 2.4201e-35, 9.9345e-38,\n",
      "         1.9267e-29, 9.3427e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6622e-40, 9.8844e-35, 8.2238e-41, 5.5089e-40, 1.3296e-39, 3.2266e-41,\n",
      "         8.4078e-44, 6.7386e-41, 1.6657e-39, 5.8821e-33, 1.0085e-41, 3.2090e-43,\n",
      "         3.8888e-39, 9.6527e-40, 8.5034e-41, 4.8108e-39, 5.9199e-39, 1.4293e-42,\n",
      "         3.7180e-39, 1.4173e-39, 1.1643e-40, 1.3407e-38, 2.1575e-38, 2.0075e-27,\n",
      "         2.9282e-40, 1.1134e-39, 1.5293e-36, 2.2825e-37, 2.4192e-35, 9.9946e-38,\n",
      "         1.9338e-29, 9.3689e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6674e-40, 9.8896e-35, 8.2333e-41, 5.5212e-40, 1.3284e-39, 3.2245e-41,\n",
      "         8.4078e-44, 6.7481e-41, 1.6724e-39, 5.9041e-33, 1.0073e-41, 3.2090e-43,\n",
      "         3.8956e-39, 9.6676e-40, 8.5354e-41, 4.8232e-39, 5.9379e-39, 1.4349e-42,\n",
      "         3.7244e-39, 1.4236e-39, 1.1700e-40, 1.3431e-38, 2.1643e-38, 2.0159e-27,\n",
      "         2.9410e-40, 1.1158e-39, 1.5326e-36, 2.2845e-37, 2.4200e-35, 1.0052e-37,\n",
      "         1.9407e-29, 9.3967e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6725e-40, 9.8989e-35, 8.2433e-41, 5.5343e-40, 1.3277e-39, 3.2227e-41,\n",
      "         8.4078e-44, 6.7599e-41, 1.6791e-39, 5.9264e-33, 1.0066e-41, 3.2230e-43,\n",
      "         3.9024e-39, 9.6856e-40, 8.5692e-41, 4.8364e-39, 5.9567e-39, 1.4405e-42,\n",
      "         3.7309e-39, 1.4296e-39, 1.1757e-40, 1.3459e-38, 2.1712e-38, 2.0239e-27,\n",
      "         2.9542e-40, 1.1186e-39, 1.5364e-36, 2.2873e-37, 2.4220e-35, 1.0106e-37,\n",
      "         1.9476e-29, 9.4260e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.6776e-40, 9.9115e-35, 8.2535e-41, 5.5478e-40, 1.3276e-39, 3.2216e-41,\n",
      "         8.5479e-44, 6.7730e-41, 1.6858e-39, 5.9487e-33, 1.0063e-41, 3.2370e-43,\n",
      "         3.9094e-39, 9.7061e-40, 8.6044e-41, 4.8501e-39, 5.9761e-39, 1.4461e-42,\n",
      "         3.7375e-39, 1.4353e-39, 1.1813e-40, 1.3490e-38, 2.1783e-38, 2.0314e-27,\n",
      "         2.9676e-40, 1.1215e-39, 1.5405e-36, 2.2906e-37, 2.4252e-35, 1.0158e-37,\n",
      "         1.9545e-29, 9.4561e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5688e-40, 9.9611e-35, 7.9430e-41, 5.4090e-40, 1.2882e-39, 3.3156e-41,\n",
      "         7.9874e-44, 6.5051e-41, 1.5496e-39, 5.5358e-33, 1.0521e-41, 3.0829e-43,\n",
      "         3.8710e-39, 9.5837e-40, 8.0621e-41, 4.6574e-39, 5.5348e-39, 1.3607e-42,\n",
      "         3.5902e-39, 1.3174e-39, 1.1137e-40, 1.2914e-38, 2.1123e-38, 1.8840e-27,\n",
      "         2.7710e-40, 1.0727e-39, 1.4877e-36, 2.2385e-37, 2.4335e-35, 9.2243e-38,\n",
      "         1.8718e-29, 9.3050e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5667e-40, 9.9927e-35, 7.9330e-41, 5.4004e-40, 1.2840e-39, 3.3170e-41,\n",
      "         7.9874e-44, 6.4876e-41, 1.5550e-39, 5.5440e-33, 1.0606e-41, 3.0829e-43,\n",
      "         3.8828e-39, 9.6981e-40, 8.0538e-41, 4.6499e-39, 5.5220e-39, 1.3621e-42,\n",
      "         3.5803e-39, 1.3150e-39, 1.1109e-40, 1.3006e-38, 2.1165e-38, 1.8760e-27,\n",
      "         2.7756e-40, 1.0738e-39, 1.4874e-36, 2.2525e-37, 2.4429e-35, 9.1631e-38,\n",
      "         1.8686e-29, 9.3613e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5670e-40, 1.0005e-34, 7.9363e-41, 5.4004e-40, 1.2821e-39, 3.3204e-41,\n",
      "         7.9874e-44, 6.4849e-41, 1.5605e-39, 5.5528e-33, 1.0639e-41, 3.0829e-43,\n",
      "         3.8923e-39, 9.7354e-40, 8.0655e-41, 4.6460e-39, 5.5151e-39, 1.3635e-42,\n",
      "         3.5798e-39, 1.3153e-39, 1.1101e-40, 1.3052e-38, 2.1221e-38, 1.8733e-27,\n",
      "         2.7790e-40, 1.0740e-39, 1.4889e-36, 2.2524e-37, 2.4447e-35, 9.1719e-38,\n",
      "         1.8715e-29, 9.3815e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5679e-40, 1.0016e-34, 7.9402e-41, 5.4012e-40, 1.2816e-39, 3.3205e-41,\n",
      "         7.9874e-44, 6.4855e-41, 1.5649e-39, 5.5611e-33, 1.0653e-41, 3.0829e-43,\n",
      "         3.8962e-39, 9.7564e-40, 8.0768e-41, 4.6458e-39, 5.5150e-39, 1.3635e-42,\n",
      "         3.5784e-39, 1.3164e-39, 1.1102e-40, 1.3082e-38, 2.1254e-38, 1.8717e-27,\n",
      "         2.7822e-40, 1.0745e-39, 1.4908e-36, 2.2518e-37, 2.4456e-35, 9.1903e-38,\n",
      "         1.8748e-29, 9.3922e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5555e-40, 9.8524e-35, 7.7949e-41, 5.3057e-40, 1.2388e-39, 3.2764e-41,\n",
      "         7.8473e-44, 6.3186e-41, 1.5809e-39, 5.6195e-33, 1.0492e-41, 3.0128e-43,\n",
      "         3.8906e-39, 9.8470e-40, 7.9711e-41, 4.5344e-39, 5.4040e-39, 1.3509e-42,\n",
      "         3.5367e-39, 1.3343e-39, 1.1023e-40, 1.3099e-38, 2.1529e-38, 1.8602e-27,\n",
      "         2.7725e-40, 1.0608e-39, 1.4601e-36, 2.1971e-37, 2.3618e-35, 9.4248e-38,\n",
      "         1.9052e-29, 9.5661e-39, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "         0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[9.7334e-41, 4.5716e-34, 4.4843e-41, 1.0710e-40, 9.4887e-40, 2.2442e-41,\n",
      "         2.8026e-44, 8.3285e-41, 1.8379e-39, 9.5613e-33, 6.2260e-42, 1.8357e-43,\n",
      "         1.5336e-39, 4.3811e-40, 3.4552e-41, 2.7223e-39, 2.1699e-39, 1.4433e-43,\n",
      "         2.8909e-39, 8.7433e-40, 1.1131e-40, 6.4375e-39, 2.6292e-38, 3.2334e-27,\n",
      "         1.6611e-40, 6.9539e-40, 1.3616e-36, 1.5179e-37, 3.7013e-35, 2.6588e-37,\n",
      "         1.4355e-28, 1.1264e-38, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1111, 0.1111, 0.1111, 0.1111,\n",
      "         0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[2.8570e-40, 4.5342e-33, 2.7087e-41, 1.0261e-40, 7.1504e-40, 4.7808e-41,\n",
      "         3.0829e-44, 1.6771e-40, 3.8094e-39, 2.5228e-32, 2.7827e-41, 3.2230e-43,\n",
      "         2.2185e-39, 1.0376e-39, 1.1889e-40, 3.5202e-39, 4.7188e-39, 1.0089e-43,\n",
      "         6.1567e-39, 2.7535e-39, 3.7099e-40, 2.1804e-38, 2.2193e-38, 3.4701e-27,\n",
      "         3.3228e-40, 1.2652e-39, 2.8617e-35, 4.9038e-37, 2.3203e-34, 9.2577e-37,\n",
      "         5.5516e-27, 5.2524e-38, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1250, 0.1250, 0.1250,\n",
      "         0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[8.1065e-40, 1.0764e-32, 1.3406e-41, 2.7361e-40, 1.9936e-39, 4.7931e-41,\n",
      "         5.8855e-44, 2.2817e-40, 5.4610e-39, 4.5812e-32, 7.4665e-41, 2.0697e-42,\n",
      "         6.2770e-39, 2.9137e-39, 2.0218e-40, 2.0277e-38, 2.0255e-38, 3.6434e-44,\n",
      "         1.5877e-38, 9.5530e-39, 9.1304e-40, 4.6522e-38, 1.7865e-37, 8.6749e-27,\n",
      "         9.6063e-40, 2.7739e-39, 9.1940e-35, 1.0585e-36, 2.6126e-33, 6.0061e-36,\n",
      "         4.3526e-25, 3.7517e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1429, 0.1429,\n",
      "         0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[4.0729e-40, 5.9113e-33, 4.1773e-42, 1.8783e-41, 5.6453e-40, 1.2535e-41,\n",
      "         2.2421e-44, 2.5339e-40, 9.2617e-40, 5.8283e-32, 4.7306e-41, 4.2459e-43,\n",
      "         1.6365e-39, 1.1946e-39, 1.4258e-40, 9.3607e-39, 1.4112e-38, 1.4013e-45,\n",
      "         4.2777e-39, 9.0589e-39, 2.0205e-40, 2.1904e-38, 9.0932e-38, 5.6805e-27,\n",
      "         3.5429e-40, 4.4643e-40, 1.4327e-34, 1.1798e-36, 2.7364e-33, 1.1805e-35,\n",
      "         1.2117e-23, 1.5030e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1667,\n",
      "         0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[3.6316e-40, 9.0320e-33, 5.0433e-42, 5.5870e-42, 3.2951e-40, 9.3845e-42,\n",
      "         7.0065e-45, 9.3447e-41, 4.3966e-40, 6.7832e-32, 3.1578e-41, 1.6255e-43,\n",
      "         3.1036e-39, 1.1428e-39, 1.7087e-40, 8.9582e-39, 1.3684e-38, 0.0000e+00,\n",
      "         6.6315e-39, 1.0270e-38, 8.7092e-41, 7.6244e-38, 5.7285e-38, 3.5042e-26,\n",
      "         4.4854e-40, 2.2232e-40, 9.9885e-35, 9.9595e-37, 5.9976e-33, 1.3754e-35,\n",
      "         1.1907e-22, 2.0404e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[2.2078e-40, 1.2456e-32, 2.7620e-42, 2.3640e-42, 9.6435e-41, 6.3703e-42,\n",
      "         7.0065e-45, 1.1333e-40, 1.6830e-40, 7.3762e-32, 6.6936e-41, 1.3873e-43,\n",
      "         4.9477e-39, 1.2923e-39, 2.1540e-40, 1.4365e-38, 6.3326e-39, 0.0000e+00,\n",
      "         6.1336e-39, 1.1338e-38, 2.8089e-41, 5.6845e-38, 5.1456e-38, 1.0350e-25,\n",
      "         2.5169e-40, 2.6692e-40, 9.5077e-35, 5.2497e-37, 7.6444e-33, 1.4600e-35,\n",
      "         3.8852e-22, 4.4779e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.2500, 0.2500, 0.2500, 0.2500, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[1.5629e-40, 1.2612e-32, 6.8944e-43, 2.8054e-42, 6.2096e-41, 4.9144e-42,\n",
      "         5.6052e-45, 6.8445e-41, 7.6418e-41, 2.8898e-32, 2.7548e-41, 7.2868e-44,\n",
      "         3.0716e-39, 6.6812e-40, 7.3211e-41, 1.6303e-38, 1.0770e-38, 0.0000e+00,\n",
      "         1.3456e-39, 5.8671e-39, 3.0513e-41, 8.3474e-38, 5.6979e-38, 1.1522e-25,\n",
      "         2.0756e-40, 1.8956e-40, 6.0823e-35, 5.2332e-37, 4.2070e-33, 1.5635e-35,\n",
      "         1.0588e-21, 8.0721e-37, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.3333, 0.3333, 0.3333, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[8.6325e-40, 3.9115e-32, 2.4158e-42, 3.4934e-42, 1.4329e-40, 8.6796e-42,\n",
      "         1.9618e-44, 1.2184e-40, 3.1138e-40, 1.1568e-31, 6.3866e-41, 2.7325e-43,\n",
      "         6.0073e-39, 1.3125e-39, 2.1393e-40, 5.7819e-38, 4.1338e-38, 0.0000e+00,\n",
      "         6.7013e-39, 1.1396e-38, 1.4052e-40, 1.8173e-37, 1.8504e-37, 6.5201e-25,\n",
      "         1.9266e-40, 1.7219e-39, 2.5240e-34, 3.3843e-36, 7.8517e-33, 3.1751e-35,\n",
      "         7.4816e-21, 8.0428e-36, 1.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.5000, 0.5000, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.4314, 0.4885, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0230, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0232, 0.0339, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.7353, 0.1295, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0387, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0392, 0.0573, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.3841, 0.3115, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0856, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0868, 0.1320, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.4557, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1170, 0.1188, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1206, 0.1879, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1744, 0.1771, 0.1798, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1826, 0.2861, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 364.69it/s, loss=2.977266483306885]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0279, 0.0284, 0.0290, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0296, 0.8852, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1424, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0673, 0.1308, 0.5186, 0.1410, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2857, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1345, 0.2624, 0.0000, 0.2829, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0345, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0464, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1792, 0.3509, 0.0000, 0.3784, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0451, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0681, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2684, 0.5274, 0.0000, 0.0699, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0662, 0.0000]])\n",
      "==================\n",
      "==================\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1237, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.4982, 0.1307, 0.0000, 0.1272, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1201, 0.0000]])\n",
      "==================\n",
      "hit rate 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "h, c = None, None\n",
    "buffer = [Page(-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1)] * BUFFER_SIZE\n",
    "\n",
    "hits = 0\n",
    "\n",
    "loss_sum = 0\n",
    "step = 1\n",
    "pbar = tqdm(range(0, 100, step))\n",
    "for i in pbar:\n",
    "    batch_start = i\n",
    "    # batch_end = i + BATCH_SIZE if i + BATCH_SIZE < TRAIN_SIZE else TRAIN_SIZE\n",
    "    batch_end = i + step \n",
    "    if batch_end >= TRAIN_SIZE:\n",
    "        continue\n",
    "    pages_acc, buffers, optimal_predictions, buffer = get_train_data(pages, buffer, batch_start, batch_end)\n",
    "    hits += hits_count\n",
    "\n",
    "    out, h, c = model.forward(pages_acc, buffers, h, c)\n",
    "    print(\"==================\")\n",
    "    print(out)\n",
    "    print(optimal_predictions)\n",
    "    print(\"==================\")\n",
    "\n",
    "    loss_value = loss(out, optimal_predictions)\n",
    "\n",
    "    loss_sum += loss_value.item()\n",
    "    loss_avg = loss_sum / (batch_end // step)\n",
    "\n",
    "    pbar.set_postfix_str(f\"loss={loss_avg}\")\n",
    "\n",
    "print(f\"hit rate {hits / len(pbar)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
