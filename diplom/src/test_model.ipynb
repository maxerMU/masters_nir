{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, fields, asdict\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from model.model import PageAccModel\n",
    "from logfile_reader import read_pages, save_pages_accs, read_optimal_results, Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 32\n",
    "TRAIN_PART = 0.7\n",
    "RESULTS_DIR = \"results/data/tpcc_32/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = read_pages(RESULTS_DIR + \"logfile\")\n",
    "train_size = int(len(pages) * TRAIN_PART)\n",
    "test_size = len(pages) - train_size\n",
    "train_pages = pages[:train_size]\n",
    "test_pages = pages[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPageVictimStrategy(ABC):\n",
    "    @abstractmethod\n",
    "    def forward(page: Page, buffer: list[Page]):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(pages: list[Page], evict_strategy: IPageVictimStrategy):\n",
    "    buffer = [Page(-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 0)] * BUFFER_SIZE\n",
    "\n",
    "    hits = 0\n",
    "    hit_rates = []\n",
    "    pbar = tqdm(range(len(pages)))\n",
    "    for i in pbar:\n",
    "        page = pages[i]\n",
    "        victim = evict_strategy.forward(page, buffer)\n",
    "        if victim < 0:\n",
    "            hits += 1\n",
    "        else:\n",
    "            # buffer[victim] = deepcopy(page)\n",
    "            buffer[victim] = page\n",
    "            buffer[victim].hit = victim\n",
    "        \n",
    "        hit_rates.append(hits / (i + 1))\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            pbar.set_postfix_str(f\"hit_rate={hits / (i + 1)}\")\n",
    "    \n",
    "    return hit_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelVictimStrategy(IPageVictimStrategy):\n",
    "    def __init__(self, model: PageAccModel):\n",
    "        self._model = model\n",
    "        self._h = None\n",
    "        self._c = None\n",
    "\n",
    "        self._model.eval()\n",
    "\n",
    "    def forward(self, page: Page, buffer: list[Page]):\n",
    "        page_tensor = torch.Tensor(list(asdict(page).values()))\n",
    "        page_in_buffer = next(filter(lambda x: x[1].buffer == page.buffer, enumerate(buffer)), None)\n",
    "        page_already_in_buf = page_in_buffer is not None\n",
    "        if page_already_in_buf:\n",
    "            page_tensor[-1] = int(page_in_buffer[0])\n",
    "        page_tensor = page_tensor.view(1, len(page_tensor))\n",
    "\n",
    "        buffer_tensor = torch.Tensor([value for obj in buffer for value in asdict(obj).values()])\n",
    "        buffer_tensor = buffer_tensor.view(1, len(buffer_tensor))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out, self._h, self._c = self._model.forward(page_tensor, buffer_tensor, page_already_in_buf, self._h, self._c)\n",
    "\n",
    "        self._h.detach()\n",
    "        self._c.detach()\n",
    "\n",
    "        if page_already_in_buf:\n",
    "            return -1\n",
    "\n",
    "        return torch.argmax(out, dim=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PageAccModel(11, 512, 1024, 32)\n",
    "model.load_state_dict(torch.load(RESULTS_DIR + \"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "model_evict_strategy = ModelVictimStrategy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1248/307221 [00:14<57:18, 89.00it/s, hit_rate=0.2127872127872128]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hit_rate \u001b[38;5;241m=\u001b[39m \u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_evict_strategy\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m, in \u001b[0;36mget_metrics\u001b[0;34m(pages, evict_strategy)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[1;32m      8\u001b[0m     page \u001b[38;5;241m=\u001b[39m pages[i]\n\u001b[0;32m----> 9\u001b[0m     victim \u001b[38;5;241m=\u001b[39m \u001b[43mevict_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m victim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m         hits \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mModelVictimStrategy.forward\u001b[0;34m(self, page, buffer)\u001b[0m\n\u001b[1;32m     18\u001b[0m buffer_tensor \u001b[38;5;241m=\u001b[39m buffer_tensor\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(buffer_tensor))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 21\u001b[0m     out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage_already_in_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/repos/masters_nir/diplom/src/model/model.py:69\u001b[0m, in \u001b[0;36mPageAccModel.forward\u001b[0;34m(self, page_params, buf_pages, page_already_in_buf, h0, c0)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, hn, cn\n\u001b[1;32m     67\u001b[0m lstm_out_flat \u001b[38;5;241m=\u001b[39m lstm_out\u001b[38;5;241m.\u001b[39mview(lstm_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], lstm_out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m---> 69\u001b[0m buf_page_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buf_page_enc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf_pages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# for i in range(len(lstm_out)):\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#     for el in lstm_out[i]:\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#         self._trace_file.write(f\"{i}. ===================\\n\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#         self._trace_file.write(f\"buf_page_out\\n{buf_page_out[i]}\\n\")\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#         self._trace_file.write(\"===================\\n\")\u001b[39;00m\n\u001b[1;32m     81\u001b[0m page_evict_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((lstm_out_flat, buf_page_out), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/repos/masters_nir/diplom/src/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/masters_nir/diplom/src/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/repos/masters_nir/diplom/src/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/repos/masters_nir/diplom/src/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hit_rate = get_metrics(test_pages, model_evict_strategy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
